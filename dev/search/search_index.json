{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Introduction","text":"Hishel <p> Elegant HTTP Caching for Python </p> <p> </p> <p>Hishel (\u0570\u056b\u0577\u0565\u056c, to remember in Armenian) is a modern HTTP caching library for Python that implements RFC 9111 specifications. It provides seamless caching integration for popular HTTP clients with minimal code changes.</p>"},{"location":"#features","title":"\u2728 Features","text":"<ul> <li>\ud83c\udfaf RFC 9111 Compliant - Fully compliant with the latest HTTP caching specification</li> <li>\ud83d\udd0c Easy Integration - Drop-in support for HTTPX, Requests, ASGI, FastAPI, and BlackSheep</li> <li>\ud83d\udcbe Flexible Storage - SQLite backend with more coming soon</li> <li>\u26a1 High Performance - Efficient caching with minimal overhead</li> <li>\ud83d\udd04 Async &amp; Sync - Full support for both synchronous and asynchronous workflows</li> <li>\ud83c\udfa8 Type Safe - Fully typed with comprehensive type hints</li> <li>\ud83e\uddea Well Tested - Extensive test coverage and battle-tested</li> <li>\ud83c\udf9b\ufe0f Configurable - Fine-grained control over caching behavior with flexible policies</li> <li>\ud83d\udca8 Memory Efficient - Streaming support prevents loading large payloads into memory</li> <li>\ud83c\udf10 Universal - Works with any ASGI application (Starlette, Litestar, BlackSheep, etc.)</li> <li>\ud83c\udfaf GraphQL Support - Cache GraphQL queries with body-sensitive content caching</li> </ul>"},{"location":"#installation","title":"\ud83d\udce6 Installation","text":"<pre><code>pip install hishel\n</code></pre>"},{"location":"#optional-dependencies","title":"Optional Dependencies","text":"<p>Install with specific integration support:</p> <pre><code>pip install hishel[httpx]      # For HTTPX support\npip install hishel[requests]   # For Requests support\npip install hishel[fastapi]    # For FastAPI support (includes ASGI)\n</code></pre> <p>Or install multiple:</p> <pre><code>pip install hishel[httpx,requests,fastapi]\n</code></pre> <p>Note</p> <p>ASGI middleware has no extra dependencies - it's included in the base installation.</p>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"#with-httpx","title":"With HTTPX","text":"<p>Synchronous:</p> <pre><code>from hishel.httpx import SyncCacheClient\n\nclient = SyncCacheClient()\n\n# First request - fetches from origin\nresponse = client.get(\"https://api.example.com/data\")\nprint(response.extensions[\"hishel_from_cache\"])  # False\n\n# Second request - served from cache\nresponse = client.get(\"https://api.example.com/data\")\nprint(response.extensions[\"hishel_from_cache\"])  # True\n</code></pre> <p>Asynchronous:</p> <pre><code>from hishel.httpx import AsyncCacheClient\n\nasync with AsyncCacheClient() as client:\n    # First request - fetches from origin\n    response = await client.get(\"https://api.example.com/data\")\n    print(response.extensions[\"hishel_from_cache\"])  # False\n\n    # Second request - served from cache\n    response = await client.get(\"https://api.example.com/data\")\n    print(response.extensions[\"hishel_from_cache\"])  # True\n</code></pre>"},{"location":"#with-requests","title":"With Requests","text":"<pre><code>import requests\nfrom hishel.requests import CacheAdapter\n\nsession = requests.Session()\nsession.mount(\"https://\", CacheAdapter())\nsession.mount(\"http://\", CacheAdapter())\n\n# First request - fetches from origin\nresponse = session.get(\"https://api.example.com/data\")\n\n# Second request - served from cache\nresponse = session.get(\"https://api.example.com/data\")\nprint(response.headers.get(\"X-Hishel-From-Cache\"))  # \"True\"\n</code></pre>"},{"location":"#with-asgi-applications","title":"With ASGI Applications","text":"<p>Add caching middleware to any ASGI application:</p> <pre><code>from hishel.asgi import ASGICacheMiddleware\n\n# Wrap your ASGI app\napp = ASGICacheMiddleware(app)\n\n# Or configure with options\nfrom hishel import AsyncSqliteStorage, CacheOptions, SpecificationPolicy\n\napp = ASGICacheMiddleware(\n    app,\n    storage=AsyncSqliteStorage(),\n    policy=SpecificationPolicy(\n      cache_options=CacheOptions(shared=True)\n    )\n)\n</code></pre>"},{"location":"#with-fastapi","title":"With FastAPI","text":"<p>Add Cache-Control headers using the <code>cache()</code> dependency:</p> <pre><code>from fastapi import FastAPI\nfrom hishel.fastapi import cache\n\napp = FastAPI()\n\n@app.get(\"/api/data\", dependencies=[cache(max_age=300, public=True)])\nasync def get_data():\n    # Cache-Control: public, max-age=300\n    return {\"data\": \"cached for 5 minutes\"}\n\n# Optionally wrap with ASGI middleware for local caching according to specified rules\nfrom hishel.asgi import ASGICacheMiddleware\nfrom hishel import AsyncSqliteStorage\n\napp = ASGICacheMiddleware(app, storage=AsyncSqliteStorage())\n</code></pre>"},{"location":"#with-blacksheep","title":"With BlackSheep","text":"<p>Use BlackSheep's native <code>cache_control</code> decorator with Hishel's ASGI middleware:</p> <pre><code>from blacksheep import Application, get\nfrom blacksheep.server.headers.cache import cache_control\n\napp = Application()\n\n@get(\"/api/data\")\n@cache_control(max_age=300, public=True)\nasync def get_data():\n    # Cache-Control: public, max-age=300\n    return {\"data\": \"cached for 5 minutes\"}\n</code></pre>"},{"location":"#advanced-configuration","title":"\ud83c\udf9b\ufe0f Advanced Configuration","text":""},{"location":"#caching-policies","title":"Caching Policies","text":"<p>Hishel supports two types of caching policies for flexible caching strategies:</p>"},{"location":"#specificationpolicy-rfc-9111-compliant","title":"SpecificationPolicy (RFC 9111 Compliant)","text":"<p>The default policy that follows HTTP caching standards:</p> <pre><code>from hishel import CacheOptions, SpecificationPolicy\nfrom hishel.httpx import SyncCacheClient\n\nclient = SyncCacheClient(\n    policy=SpecificationPolicy(\n      cache_options=CacheOptions(\n          shared=False,                              # Use as private cache (browser-like)\n          supported_methods=[\"GET\", \"HEAD\", \"POST\"], # Cache GET, HEAD, and POST\n          allow_stale=True                           # Allow serving stale responses\n      )\n    )\n)\n</code></pre>"},{"location":"#filterpolicy-custom-filtering","title":"FilterPolicy (Custom Filtering)","text":"<p>Apply custom logic to determine what gets cached:</p> <pre><code>from hishel import FilterPolicy, BaseFilter, Request\nfrom hishel.httpx import AsyncCacheClient\n\nclass CacheOnlyAPIRequests(BaseFilter[Request]):\n    def needs_body(self) -&gt; bool:\n        return False\n\n    def apply(self, item: Request, body: bytes | None) -&gt; bool:\n        # Only cache requests to /api/ endpoints\n        return \"/api/\" in str(item.url)\n\nclient = AsyncCacheClient(\n    policy=FilterPolicy(\n        request_filters=[CacheOnlyAPIRequests()]\n    )\n)\n</code></pre> <p>Learn More</p> <p>See the Policies Guide for detailed examples including GraphQL caching, body inspection, and combining multiple filters.</p>"},{"location":"#custom-storage-backend","title":"Custom Storage Backend","text":"<pre><code>from hishel import SyncSqliteStorage\nfrom hishel.httpx import SyncCacheClient\n\nstorage = SyncSqliteStorage(\n    database_path=\"my_cache.db\",\n    default_ttl=7200.0,           # Cache entries expire after 2 hours\n    refresh_ttl_on_access=True    # Reset TTL when accessing cached entries\n)\n\nclient = SyncCacheClient(storage=storage)\n</code></pre>"},{"location":"#graphql-and-body-sensitive-caching","title":"GraphQL and Body-Sensitive Caching","text":"<p>Cache GraphQL queries and other POST requests by including the request body in the cache key.</p> <p>Using per-request header:</p> <pre><code>from hishel.httpx import SyncCacheClient\n\nclient = SyncCacheClient()\n\n# Cache GraphQL queries - different queries get different cache entries\ngraphql_query = \"\"\"\n    query GetUser($id: ID!) {\n        user(id: $id) {\n            name\n            email\n        }\n    }\n\"\"\"\n\nresponse = client.post(\n    \"https://api.example.com/graphql\",\n    json={\"query\": graphql_query, \"variables\": {\"id\": \"123\"}},\n    headers={\"X-Hishel-Body-Key\": \"true\"}  # Enable body-based caching\n)\n\n# Different query will be cached separately\nresponse = client.post(\n    \"https://api.example.com/graphql\",\n    json={\"query\": graphql_query, \"variables\": {\"id\": \"456\"}},\n    headers={\"X-Hishel-Body-Key\": \"true\"}\n)\n</code></pre> <p>Using global configuration:</p> <pre><code>from hishel.httpx import SyncCacheClient\nfrom hishel import FilterPolicy\n\n# Enable body-based caching for all requests\nclient = SyncCacheClient(policy=FilterPolicy(use_body_key=True))\n\n# All POST requests automatically include body in cache key\nresponse = client.post(\n    \"https://api.example.com/graphql\",\n    json={\"query\": graphql_query, \"variables\": {\"id\": \"123\"}}\n)\n</code></pre>"},{"location":"#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<p>Hishel uses a sans-I/O state machine architecture that separates HTTP caching logic from I/O operations:</p> <ul> <li>\u2705 Correct - Fully RFC 9111 compliant</li> <li>\u2705 Testable - Easy to test without network dependencies</li> <li>\u2705 Flexible - Works with any HTTP client or server</li> <li>\u2705 Type Safe - Clear state transitions with full type hints</li> </ul>"},{"location":"#roadmap","title":"\ud83d\udd2e Roadmap","text":"<p>We're actively working on:</p> <ul> <li>\ud83c\udfaf Performance optimizations</li> <li>\ud83c\udfaf More integrations</li> <li>\ud83c\udfaf Partial responses support</li> </ul>"},{"location":"#documentation","title":"\ud83d\udcda Documentation","text":"<p>Comprehensive documentation is available at https://hishel.com/dev</p> <ul> <li>Getting Started</li> <li>HTTPX Integration</li> <li>Requests Integration</li> <li>ASGI Integration</li> <li>FastAPI Integration</li> <li>BlackSheep Integration</li> <li>GraphQL Integration</li> <li>Storage Backends</li> <li>Request/Response Metadata</li> <li>RFC 9111 Specification</li> </ul>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.</p> <p>See our Contributing Guide for more details.</p>"},{"location":"#license","title":"\ud83d\udcc4 License","text":"<p>This project is licensed under the BSD-3-Clause License - see the LICENSE file for details.</p>"},{"location":"#support","title":"\ud83d\udc96 Support","text":"<p>If you find Hishel useful, please consider:</p> <ul> <li>\u2b50 Starring the repository</li> <li>\ud83d\udc1b Reporting bugs and issues</li> <li>\ud83d\udca1 Suggesting new features</li> <li>\ud83d\udcd6 Improving documentation</li> <li>\u2615 Buying me a coffee</li> </ul>"},{"location":"#acknowledgments","title":"\ud83d\ude4f Acknowledgments","text":"<p>Hishel is inspired by and builds upon the excellent work in the Python HTTP ecosystem, particularly:</p> <ul> <li>HTTPX - A next-generation HTTP client for Python</li> <li>Requests - The classic HTTP library for Python</li> <li>RFC 9111 - HTTP Caching specification</li> </ul> <p> Made with \u2764\ufe0f by Kar Petrosyan </p>"},{"location":"contributing/","title":"Contributing to Hishel","text":"<p>Thank you for being interested in contributing to <code>Hishel</code>! We appreciate your efforts and welcome contributions of all kinds.</p> <p>You can contribute by:</p> <ul> <li>Reviewing pull requests</li> <li>Opening an issue to report bugs or suggest features</li> <li>Adding a new feature</li> <li>\u2b50 Starring the repository on GitHub - it helps the project grow!</li> </ul> <p>This guide will help you understand the development process and repository structure.</p>"},{"location":"contributing/#getting-started","title":"Getting Started","text":""},{"location":"contributing/#setting-up-your-development-environment","title":"Setting Up Your Development Environment","text":"<ol> <li> <p>Fork the repository: Fork Hishel to your GitHub account</p> </li> <li> <p>Clone and create a branch: <pre><code>git clone https://github.com/username/hishel\ncd hishel\ngit switch -c my-feature-name\n</code></pre></p> </li> <li> <p>Install dependencies: This project uses <code>uv</code> for dependency management. Make sure you have it installed, then install the project dependencies: <pre><code>uv sync --all-extras --dev\n</code></pre></p> </li> </ol>"},{"location":"contributing/#repository-structure","title":"Repository Structure","text":""},{"location":"contributing/#the-scripts-folder","title":"The <code>scripts/</code> Folder","text":"<p>The <code>scripts/</code> directory contains utility scripts to simplify development and maintenance tasks:</p> <ul> <li><code>scripts/fix</code> - Automatically fixes code style issues, formats code, and generates synchronous code from async code</li> <li><code>scripts/lint</code> - Validates code quality (linting, formatting, type checking, async/sync consistency)</li> <li><code>scripts/test</code> - Runs the test suite with coverage reporting</li> <li><code>scripts/unasync</code> - Converts async code to sync code (see below for details)</li> </ul>"},{"location":"contributing/#usage-example","title":"Usage Example","text":"<pre><code># Fix code style and generate sync files\n./scripts/fix\n\n# Check code quality\n./scripts/lint\n\n# Run tests with coverage\n./scripts/test\n</code></pre>"},{"location":"contributing/#critical-asyncsync-code-generation","title":"Critical: Async/Sync Code Generation","text":"<p>\u26a0\ufe0f IMPORTANT: Do not manually edit auto-generated synchronous files!</p> <p>Hishel maintains both async and sync APIs without code duplication using an unasync strategy similar to httpcore.</p>"},{"location":"contributing/#how-it-works","title":"How It Works","text":"<p>Write async code once - All shared async/sync functionality is written in async files:</p> <ul> <li><code>hishel/_core/_storages/_async_*.py</code> \u2192 auto-generates \u2192 <code>hishel/_core/_storages/_sync_*.py</code></li> <li><code>tests/_core/_async/*.py</code> \u2192 auto-generates \u2192 <code>tests/_core/_sync/*.py</code></li> </ul> <p>Automatic transformation - The <code>scripts/unasync</code> script converts async code to sync:</p> <pre><code># Async code (you write this)\nasync def store(self, key: str) -&gt; None:\n    async with self.connection as conn:\n        await conn.execute(...)\n\n# Sync code (automatically generated)\ndef store(self, key: str) -&gt; None:\n    with self.connection as conn:\n        conn.execute(...)\n</code></pre>"},{"location":"contributing/#using-the-script","title":"Using the Script","text":"<pre><code># Generate sync files from async files\n./scripts/unasync\n\n# Check if sync files are up-to-date (CI)\n./scripts/unasync --check\n\n# Or use helper scripts\n./scripts/fix     # Auto-generates sync files + formatting\n./scripts/lint    # Checks sync files are up-to-date\n</code></pre>"},{"location":"contributing/#development-rules","title":"Development Rules","text":"<p>\u2705 DO: - Write and edit async files only (<code>_async_*.py</code>) - Run <code>./scripts/fix</code> before committing - Let the script generate all sync files</p> <p>\u274c DON'T: - Manually edit sync files (<code>_sync_*.py</code>) - Commit async changes without running unasync - Modify the sync test files directly</p>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"contributing/#before-submitting-a-pr","title":"Before Submitting a PR","text":"<ol> <li>Make your changes in the async versions of files</li> <li>Run the fix script:    <pre><code>./scripts/fix\n</code></pre></li> <li>Run the linter:    <pre><code>./scripts/lint\n</code></pre></li> <li>Run tests:    <pre><code>./scripts/test\n</code></pre></li> </ol>"},{"location":"contributing/#releasing-maintainers-only","title":"Releasing (Maintainers Only)","text":"<p>This section is for maintainers who have permissions to publish new releases.</p>"},{"location":"contributing/#release-process","title":"Release Process","text":"<ol> <li> <p>Update the version in <code>pyproject.toml</code>:    <pre><code>[project]\nversion = \"1.1.6\"  # Update to new version\n</code></pre></p> </li> <li> <p>Generate the changelog using <code>git cliff</code>:    <pre><code>git cliff --output CHANGELOG.md 0.1.3.. --tag 1.1.6\n</code></pre></p> </li> <li>Start from <code>0.1.3</code> (versions before this didn't use conventional commits)</li> <li> <p>Specify the new release tag with <code>--tag</code></p> </li> <li> <p>Commit the changes with an unconventional commit message:    <pre><code>git add pyproject.toml CHANGELOG.md\ngit commit -m \"Version 1.1.6\"\n</code></pre></p> </li> <li> <p>Create a git tag for the release:    <pre><code>git tag 1.1.6\n</code></pre></p> </li> <li> <p>Push to GitHub (both commits and tags):    <pre><code>git push\ngit push --tags\n</code></pre></p> </li> <li> <p>Ensure CI passes - Wait for all GitHub Actions workflows to complete successfully</p> </li> <li> <p>Done! - The release is published once CI passes</p> </li> </ol>"},{"location":"contributing/#questions","title":"Questions?","text":"<p>If you have questions about contributing, feel free to: - Open an issue for discussion - Ask in an existing pull request - Check the documentation</p> <p>Thank you for contributing to Hishel! \ud83c\udf89</p>"},{"location":"metadata/","title":"Request and Response Metadata","text":"<p>Metadata allows you to control caching behavior and inspect cache operations. Hishel supports metadata on both requests (to control caching) and responses (to inspect what happened).</p> <p>All metadata fields are prefixed with <code>hishel_</code> to avoid collisions with user data.</p>"},{"location":"metadata/#request-metadata","title":"Request Metadata","text":"<p>Request metadata controls how Hishel caches the request and its response. You can set metadata using:</p> <ul> <li>httpx: <code>extensions</code> parameter (recommended) or <code>X-Hishel-*</code> headers</li> <li>requests: <code>X-Hishel-*</code> headers</li> </ul> <p>httpx supports both methods</p> <p>While httpx supports both <code>extensions</code> and headers, using <code>extensions</code> is recommended as it provides better type safety and doesn't pollute HTTP headers sent to the server.</p>"},{"location":"metadata/#hishel_ttl","title":"hishel_ttl","text":"<p>Type: <code>float | None</code></p> <p>Description: Sets a custom time-to-live (TTL) for the cached response. After the specified number of seconds, the cached response will be considered expired and removed during cleanup.</p> <p>Use Cases:</p> <ul> <li>Override default TTL for specific endpoints</li> <li>Set shorter TTL for frequently changing data</li> <li>Set longer TTL for static resources</li> </ul> <p>Default: Storage's <code>default_ttl</code> setting</p> <p>Example:</p> httpx (extensions)httpx (headers)requests <pre><code>from hishel.httpx import SyncCacheClient\n\nclient = SyncCacheClient()\n\n# Cache this response for 1 hour using extensions (recommended)\nresponse = client.get(\n    \"https://api.example.com/data\",\n    extensions={\"hishel_ttl\": 3600}\n)\n</code></pre> <pre><code>from hishel.httpx import SyncCacheClient\n\nclient = SyncCacheClient()\n\n# Cache this response for 1 hour using headers\nresponse = client.get(\n    \"https://api.example.com/data\",\n    headers={\"X-Hishel-Ttl\": \"3600\"}\n)\n</code></pre> <pre><code>import requests\nfrom hishel.requests import CacheAdapter\n\nsession = requests.Session()\nsession.mount(\"http://\", CacheAdapter())\nsession.mount(\"https://\", CacheAdapter())\n\n# Cache this response for 1 hour\nresponse = session.get(\n    \"https://api.example.com/data\",\n    headers={\"X-Hishel-Ttl\": \"3600\"}\n)\n</code></pre>"},{"location":"metadata/#hishel_refresh_ttl_on_access","title":"hishel_refresh_ttl_on_access","text":"<p>Type: <code>bool | None</code></p> <p>Description: When <code>True</code>, accessing a cached entry resets its TTL, keeping frequently accessed entries fresh. When <code>False</code>, the TTL countdown starts from the original storage time and is not affected by subsequent accesses.</p> <p>Use Cases:</p> <ul> <li>Keep popular content cached longer (sliding expiration)</li> <li>Ensure rarely accessed content expires on schedule (fixed expiration)</li> </ul> <p>Default: Storage's <code>refresh_ttl_on_access</code> setting (typically <code>True</code>)</p> <p>Example:</p> httpxrequests <pre><code>from hishel.httpx import SyncCacheClient\n\nclient = SyncCacheClient()\n\n# Enable sliding expiration - each access resets the timer\nresponse = client.get(\n    \"https://api.example.com/user/profile\",\n    extensions={\"hishel_refresh_ttl_on_access\": True}\n)\n</code></pre> <pre><code>import requests\nfrom hishel.requests import CacheAdapter\n\nsession = requests.Session()\nsession.mount(\"http://\", CacheAdapter())\nsession.mount(\"https://\", CacheAdapter())\n\n# Enable sliding expiration - each access resets the timer\nresponse = session.get(\n    \"https://api.example.com/user/profile\",\n    headers={\"X-Hishel-Refresh-Ttl-On-Access\": \"true\"}\n)\n</code></pre>"},{"location":"metadata/#hishel_body_key","title":"hishel_body_key","text":"<p>Type: <code>bool | None</code></p> <p>Description: When <code>True</code>, includes the request body in cache key generation. This allows caching different responses for the same URL but with different request bodies, which is essential for POST requests and GraphQL queries.</p> <p>Use Cases:</p> <ul> <li>Cache POST requests with different payloads</li> <li>Cache GraphQL queries (different queries to same endpoint)</li> <li>Cache search requests with different parameters in body</li> </ul> <p>Default: <code>False</code> (body not included in cache key)</p> <p>Example:</p> httpxrequests <pre><code>from hishel.httpx import SyncCacheClient\n\nclient = SyncCacheClient()\n\n# Cache POST request based on body content\nresponse = client.post(\n    \"https://api.example.com/search\",\n    json={\"query\": \"python\"},\n    extensions={\"hishel_body_key\": True}\n)\n</code></pre> <pre><code>import requests\nfrom hishel.requests import CacheAdapter\n\nsession = requests.Session()\nsession.mount(\"http://\", CacheAdapter())\nsession.mount(\"https://\", CacheAdapter())\n\n# Cache POST request based on body content\nresponse = session.post(\n    \"https://api.example.com/search\",\n    json={\"query\": \"python\"},\n    headers={\"X-Hishel-Body-Key\": \"true\"}\n)\n</code></pre>"},{"location":"metadata/#response-metadata","title":"Response Metadata","text":"<p>Response metadata provides information about cache operations that occurred. These fields are read-only and set by Hishel.</p>"},{"location":"metadata/#hishel_from_cache","title":"hishel_from_cache","text":"<p>Type: <code>bool | None</code></p> <p>Description: Indicates whether the response was served from cache (<code>True</code>) or fetched from the origin server (<code>False</code>).</p> <p>Use Cases:</p> <ul> <li>Monitor cache hit rates</li> <li>Debug caching behavior</li> <li>Log cache performance</li> <li>Conditional logic based on cache status</li> </ul> <p>Example:</p> httpxrequests <pre><code>from hishel.httpx import SyncCacheClient\n\nclient = SyncCacheClient()\n\nresponse = client.get(\"https://api.example.com/data\")\n\n# Check if response came from cache\nif response.extensions.get(\"hishel_from_cache\"):\n    print(\"\u2713 Cache hit\")\nelse:\n    print(\"\u2717 Cache miss - fetched from origin\")\n</code></pre> <pre><code>import requests\nfrom hishel.requests import CacheAdapter\n\nsession = requests.Session()\nsession.mount(\"http://\", CacheAdapter())\nsession.mount(\"https://\", CacheAdapter())\n\nresponse = session.get(\"https://api.example.com/data\")\n\n# Check if response came from cache\nif response.headers.get(\"X-Hishel-From-Cache\") == \"true\":\n    print(\"\u2713 Cache hit\")\nelse:\n    print(\"\u2717 Cache miss - fetched from origin\")\n</code></pre>"},{"location":"metadata/#hishel_revalidated","title":"hishel_revalidated","text":"<p>Type: <code>bool | None</code></p> <p>Description: Indicates whether a stale cached response was revalidated with the origin server. When <code>True</code>, the response was in cache but required validation (typically resulting in a 304 Not Modified response).</p> <p>Use Cases:</p> <ul> <li>Monitor revalidation frequency</li> <li>Debug cache freshness logic</li> <li>Track conditional request behavior</li> <li>Optimize cache TTL settings</li> </ul> <p>Example:</p> httpxrequests <pre><code>from hishel.httpx import SyncCacheClient\n\nclient = SyncCacheClient()\n\nresponse = client.get(\"https://api.example.com/data\")\n\n# Check if cached response was revalidated\nif response.extensions.get(\"hishel_revalidated\"):\n    print(\"Response was revalidated (304 Not Modified)\")\n</code></pre> <pre><code>import requests\nfrom hishel.requests import CacheAdapter\n\nsession = requests.Session()\nsession.mount(\"http://\", CacheAdapter())\nsession.mount(\"https://\", CacheAdapter())\n\nresponse = session.get(\"https://api.example.com/data\")\n\n# Check if cached response was revalidated\nif response.headers.get(\"X-Hishel-Revalidated\") == \"true\":\n    print(\"Response was revalidated (304 Not Modified)\")\n</code></pre>"},{"location":"metadata/#hishel_stored","title":"hishel_stored","text":"<p>Type: <code>bool | None</code></p> <p>Description: Indicates whether the response was successfully stored in cache. When <code>True</code>, the response met all caching requirements and was saved. When <code>False</code>, the response was not cacheable (e.g., due to <code>Cache-Control: no-store</code>).</p> <p>Use Cases:</p> <ul> <li>Verify responses are being cached</li> <li>Debug why responses aren't cached</li> <li>Monitor cache storage success rate</li> <li>Validate caching configuration</li> </ul> <p>Example:</p> httpxrequests <pre><code>from hishel.httpx import SyncCacheClient\n\nclient = SyncCacheClient()\n\nresponse = client.get(\"https://api.example.com/data\")\n\n# Check if response was cached\nif response.extensions.get(\"hishel_stored\"):\n    print(\"\u2713 Response stored in cache\")\nelse:\n    print(\"\u2717 Response not cached\")\n</code></pre> <pre><code>import requests\nfrom hishel.requests import CacheAdapter\n\nsession = requests.Session()\nsession.mount(\"http://\", CacheAdapter())\nsession.mount(\"https://\", CacheAdapter())\n\nresponse = session.get(\"https://api.example.com/data\")\n\n# Check if response was cached\nif response.headers.get(\"X-Hishel-Stored\") == \"true\":\n    print(\"\u2713 Response stored in cache\")\nelse:\n    print(\"\u2717 Response not cached\")\n</code></pre>"},{"location":"metadata/#hishel_created_at","title":"hishel_created_at","text":"<p>Type: <code>float | None</code></p> <p>Description: POSIX timestamp (seconds since the epoch) indicating when the response entry was created in the cache. This value is set by Hishel when the response is stored and can be used with <code>hishel_ttl</code> to compute remaining freshness.</p> <p>Use Cases:</p> <ul> <li>Determine when an entry was cached for logging or debugging.</li> <li>Compute remaining TTL: <code>remaining = hishel_ttl - (now - hishel_created_at)</code>.</li> </ul> <p>Example (httpx extensions):</p> <pre><code>created = response.extensions.get(\"hishel_created_at\")\nif created:\n    print(\"Cached at:\", created)\n</code></pre> <p>Example (requests headers):</p> <pre><code>created = response.headers.get(\"X-Hishel-Created-At\")\nif created:\n    print(\"Cached at:\", created)\n</code></pre>"},{"location":"policies/","title":"Caching Policies","text":"<p>Hishel provides a flexible policy system that allows you to control caching behavior.  Policies determine how requests and responses are cached, giving you fine-grained control over the caching strategy.</p>"},{"location":"policies/#overview","title":"Overview","text":"<p>A policy is an object that defines the caching strategy for your HTTP client. Hishel supports two main types of policies:</p> <ol> <li>SpecificationPolicy - Follows RFC 9111 HTTP caching specification</li> <li>FilterPolicy - Applies custom user-defined filtering logic</li> </ol> <p>All policies inherit from the <code>CachePolicy</code> base class.</p>"},{"location":"policies/#specificationpolicy","title":"SpecificationPolicy","text":"<p>The <code>SpecificationPolicy</code> implements RFC 9111 compliant HTTP caching. This is the default policy used by <code>Hishel</code> when no policy is explicitly provided.</p>"},{"location":"policies/#configuration","title":"Configuration","text":"<pre><code>from hishel import CacheOptions, SpecificationPolicy\n\npolicy = SpecificationPolicy(\n    cache_options=CacheOptions(\n        shared=True,           # Act as a shared cache (proxy/CDN)\n        allow_stale=False,     # Don't serve stale responses\n        supported_methods=[\"GET\", \"HEAD\"],  # Cache these methods\n    )\n)\n</code></pre>"},{"location":"policies/#cacheoptions","title":"CacheOptions","text":"<p>The <code>SpecificationPolicy</code> accepts a <code>CacheOptions</code> object that configures how the cache behaves:</p>"},{"location":"policies/#shared","title":"shared","text":"<p>Determines whether the cache operates as a shared cache or private cache.</p> <p>RFC 9111 Section 3.5: Authenticated Responses</p> <ul> <li>Shared cache (<code>True</code>): Acts as a proxy, CDN, or gateway cache serving multiple users.</li> <li>Must respect <code>private</code> directives</li> <li>Must handle <code>Authorization</code> header restrictions</li> <li> <p>Can use <code>s-maxage</code> directive instead of <code>max-age</code></p> </li> <li> <p>Private cache (<code>False</code>): Acts as a browser or user-agent cache for a single user.</p> </li> <li>Can cache private responses</li> <li>Ignores <code>s-maxage</code> directives</li> </ul> <pre><code># Shared cache (proxy/CDN)\npolicy = SpecificationPolicy(\n    cache_options=CacheOptions(shared=True)\n)\n\n# Private cache (browser)\npolicy = SpecificationPolicy(\n    cache_options=CacheOptions(shared=False)\n)\n</code></pre>"},{"location":"policies/#supported_methods","title":"supported_methods","text":"<p>HTTP methods that are allowed to be cached.</p> <p>RFC 9111 Section 3: A cache MUST NOT store a response to a request unless the request method is understood by the cache.</p> <pre><code># Default: cache GET and HEAD only\npolicy = SpecificationPolicy(\n    cache_options=CacheOptions(\n        supported_methods=[\"GET\", \"HEAD\"]\n    )\n)\n\n# Cache POST responses (advanced use case)\npolicy = SpecificationPolicy(\n    cache_options=CacheOptions(\n        supported_methods=[\"GET\", \"HEAD\", \"POST\"]\n    )\n)\n</code></pre>"},{"location":"policies/#allow_stale","title":"allow_stale","text":"<p>Controls whether stale responses can be served without revalidation.</p> <p>RFC 9111 Section 4.2.4: Serving Stale Responses</p> <pre><code># Conservative: never serve stale\npolicy = SpecificationPolicy(\n    cache_options=CacheOptions(allow_stale=False)\n)\n\n# Permissive: serve stale when allowed by directives\npolicy = SpecificationPolicy(\n    cache_options=CacheOptions(allow_stale=True)\n)\n</code></pre>"},{"location":"policies/#usage-examples","title":"Usage Examples","text":"HTTPX (Async)HTTPX (Sync)RequestsASGI Middleware <pre><code>import httpx\nfrom hishel import AsyncCacheClient, SpecificationPolicy, CacheOptions\n\npolicy = SpecificationPolicy(\n    cache_options=CacheOptions(\n        shared=False,  # Private browser cache\n        allow_stale=False,\n    )\n)\n\nasync with AsyncCacheClient(policy=policy) as client:\n    response = await client.get(\"https://api.example.com/data\")\n</code></pre> <pre><code>import httpx\nfrom hishel import SyncCacheClient, SpecificationPolicy, CacheOptions\nfrom hishel import CacheOptions\n\npolicy = SpecificationPolicy(\n    cache_options=CacheOptions(\n        shared=True,  # Shared proxy cache\n        allow_stale=True,\n    )\n)\n\nwith SyncCacheClient(policy=policy) as client:\n    response = client.get(\"https://api.example.com/data\")\n</code></pre> <pre><code>import requests\nfrom hishel.requests import CacheAdapter\nfrom hishel import SpecificationPolicy, CacheOptions\n\npolicy = SpecificationPolicy(\n    cache_options=CacheOptions(shared=False)\n)\n\nsession = requests.Session()\nsession.mount(\"https://\", CacheAdapter(policy=policy))\nsession.mount(\"http://\", CacheAdapter(policy=policy))\n\nresponse = session.get(\"https://api.example.com/data\")\n</code></pre> <pre><code>from hishel.asgi import ASGICacheMiddleware\nfrom hishel import SpecificationPolicy, CacheOptions\n\npolicy = SpecificationPolicy(\n    cache_options=CacheOptions(\n        shared=True,  # Server-side shared cache\n        allow_stale=False,\n    )\n)\n\napp = ASGICacheMiddleware(\n    app=your_asgi_app,\n    policy=policy,\n)\n</code></pre>"},{"location":"policies/#filterpolicy","title":"FilterPolicy","text":"<p>The <code>FilterPolicy</code> allows you to implement custom caching logic by applying user-defined filters to requests and responses. This is useful when you need fine-grained control over what gets cached based on criteria beyond HTTP headers.</p>"},{"location":"policies/#configuration_1","title":"Configuration","text":"<pre><code>from hishel import FilterPolicy, BaseFilter\n\npolicy = FilterPolicy(\n    request_filters=[...],   # List of request filters\n    response_filters=[...],  # List of response filters\n)\n</code></pre>"},{"location":"policies/#creating-custom-filters","title":"Creating Custom Filters","text":"<p>Filters must inherit from <code>BaseFilter[T]</code> where <code>T</code> is either <code>Request</code> or <code>Response</code>.</p> <pre><code>from hishel import BaseFilter, Request, Response\n\nclass MyRequestFilter(BaseFilter[Request]):\n    def needs_body(self) -&gt; bool:\n        \"\"\"Return True if the filter needs access to the request body.\"\"\"\n        return False\n\n    def apply(self, item: Request, body: bytes | None) -&gt; bool:\n        \"\"\"\n        Return True to allow caching, False to bypass cache.\n\n        Args:\n            item: The request to filter\n            body: The request body (only if needs_body() returns True)\n        \"\"\"\n        # Your filtering logic here\n        return True\n\n\nclass MyResponseFilter(BaseFilter[Response]):\n    def needs_body(self) -&gt; bool:\n        \"\"\"Return True if the filter needs access to the response body.\"\"\"\n        return False\n\n    def apply(self, item: Response, body: bytes | None) -&gt; bool:\n        \"\"\"\n        Return True to cache the response, False to skip caching.\n\n        Args:\n            item: The response to filter\n            body: The response body (only if needs_body() returns True)\n        \"\"\"\n        # Your filtering logic here\n        return True\n</code></pre>"},{"location":"policies/#filter-examples","title":"Filter Examples","text":""},{"location":"policies/#filter-by-url-pattern","title":"Filter by URL Pattern","text":"<pre><code>import re\nfrom hishel import BaseFilter, FilterPolicy, Request\n\nclass URLPatternFilter(BaseFilter[Request]):\n    def __init__(self, pattern: str):\n        self.pattern = re.compile(pattern)\n\n    def needs_body(self) -&gt; bool:\n        return False\n\n    def apply(self, item: Request, body: bytes | None) -&gt; bool:\n        # Only cache requests matching the pattern\n        return bool(self.pattern.search(str(item.url)))\n\n# Cache only API endpoints\npolicy = FilterPolicy(\n    request_filters=[\n        URLPatternFilter(r'/api/.*')\n    ]\n)\n</code></pre>"},{"location":"policies/#filter-by-response-status-code","title":"Filter by Response Status Code","text":"<pre><code>from hishel import BaseFilter, FilterPolicy, Response\n\nclass StatusCodeFilter(BaseFilter[Response]):\n    def __init__(self, allowed_codes: list[int]):\n        self.allowed_codes = allowed_codes\n\n    def needs_body(self) -&gt; bool:\n        return False\n\n    def apply(self, item: Response, body: bytes | None) -&gt; bool:\n        # Only cache successful responses\n        return item.status_code in self.allowed_codes\n\n# Cache only 200 and 304 responses\npolicy = FilterPolicy(\n    response_filters=[\n        StatusCodeFilter([200, 304])\n    ]\n)\n</code></pre>"},{"location":"policies/#filter-by-content-type","title":"Filter by Content Type","text":"<pre><code>from hishel import BaseFilter, FilterPolicy, Response\n\nclass ContentTypeFilter(BaseFilter[Response]):\n    def __init__(self, allowed_types: list[str]):\n        self.allowed_types = allowed_types\n\n    def needs_body(self) -&gt; bool:\n        return False\n\n    def apply(self, item: Response, body: bytes | None) -&gt; bool:\n        content_type = item.headers.get(\"content-type\", \"\")\n        return any(allowed in content_type for allowed in self.allowed_types)\n\n# Cache only JSON and XML responses\npolicy = FilterPolicy(\n    response_filters=[\n        ContentTypeFilter([\"application/json\", \"application/xml\"])\n    ]\n)\n</code></pre>"},{"location":"policies/#filter-with-body-inspection","title":"Filter with Body Inspection","text":"<pre><code>import json\nfrom hishel import BaseFilter, FilterPolicy, Response\n\nclass JSONResponseFilter(BaseFilter[Response]):\n    def needs_body(self) -&gt; bool:\n        # We need access to the body to inspect it\n        return True\n\n    def apply(self, item: Response, body: bytes | None) -&gt; bool:\n        if body is None:\n            return False\n\n        try:\n            data = json.loads(body)\n            # Cache only if response contains 'cacheable' field set to True\n            return data.get(\"cacheable\", False)\n        except json.JSONDecodeError:\n            return False\n\npolicy = FilterPolicy(\n    response_filters=[JSONResponseFilter()]\n)\n</code></pre>"},{"location":"policies/#combining-multiple-filters","title":"Combining Multiple Filters","text":"<p>Filters are applied in sequence. All request filters must pass for the request to be checked against the cache. All response filters must pass for the response to be cached.</p> <pre><code>from hishel import FilterPolicy\n\npolicy = FilterPolicy(\n    request_filters=[\n        URLPatternFilter(r'/api/.*'),\n        MethodFilter([\"GET\", \"HEAD\"]),\n    ],\n    response_filters=[\n        StatusCodeFilter([200, 203, 204, 300, 301, 304, 404, 405, 410]),\n        ContentTypeFilter([\"application/json\"]),\n        SizeFilter(max_size=1024 * 1024),  # Max 1MB\n    ]\n)\n</code></pre>"},{"location":"policies/#complete-example-graphql-caching","title":"Complete Example: GraphQL Caching","text":"<pre><code>import json\nfrom hishel import AsyncCacheClient, FilterPolicy, BaseFilter, Request, Response\n\nclass GraphQLQueryFilter(BaseFilter[Request]):\n    \"\"\"Only cache GraphQL queries (not mutations).\"\"\"\n\n    def needs_body(self) -&gt; bool:\n        return True\n\n    def apply(self, item: Request, body: bytes | None) -&gt; bool:\n        if body is None:\n            return False\n\n        try:\n            data = json.loads(body)\n            query = data.get(\"query\", \"\")\n            # Cache only if it's a query, not a mutation\n            return \"mutation\" not in query.lower()\n        except json.JSONDecodeError:\n            return False\n\n\nclass GraphQLSuccessFilter(BaseFilter[Response]):\n    \"\"\"Only cache successful GraphQL responses (no errors).\"\"\"\n\n    def needs_body(self) -&gt; bool:\n        return True\n\n    def apply(self, item: Response, body: bytes | None) -&gt; bool:\n        if item.status_code != 200 or body is None:\n            return False\n\n        try:\n            data = json.loads(body)\n            # Cache only if there are no GraphQL errors\n            return \"errors\" not in data\n        except json.JSONDecodeError:\n            return False\n\n# Create the policy\npolicy = FilterPolicy(\n    request_filters=[GraphQLQueryFilter()],\n    response_filters=[GraphQLSuccessFilter()],\n)\n\n# Use with HTTPX\nasync with AsyncCacheClient(policy=policy) as client:\n    response = await client.post(\n        \"https://api.example.com/graphql\",\n        json={\n            \"query\": \"{ user(id: 1) { name email } }\"\n        }\n    )\n</code></pre>"},{"location":"policies/#policy-comparison","title":"Policy Comparison","text":"Feature SpecificationPolicy FilterPolicy RFC 9111 Compliance \u2705 Full \u274c None Respects Cache-Control headers \u2705 Yes \u274c No Custom filtering logic \u274c No \u2705 Yes Body inspection \u274c No \u2705 Yes Use Case Standard HTTP caching Custom caching logic Complexity Simple Moderate to Complex"},{"location":"policies/#best-practices","title":"Best Practices","text":""},{"location":"policies/#when-to-use-specificationpolicy","title":"When to Use SpecificationPolicy","text":"<ul> <li>Standard web applications: When caching public HTTP APIs that follow HTTP caching standards</li> <li>CDN/Proxy scenarios: When implementing shared caches that serve multiple users</li> <li>Browser-like caching: When you want behavior similar to a web browser's cache</li> <li>REST APIs: When working with well-designed REST APIs that use proper cache headers</li> </ul>"},{"location":"policies/#when-to-use-filterpolicy","title":"When to Use FilterPolicy","text":"<ul> <li>GraphQL APIs: When you need to inspect query bodies to determine cacheability</li> <li>Custom business logic: When caching decisions depend on application-specific rules</li> <li>Legacy APIs: When working with APIs that don't properly implement HTTP caching headers</li> <li>Fine-grained control: When you need to cache based on response content, not just headers</li> <li>POST request caching: When you want to cache POST requests based on their content</li> </ul>"},{"location":"policies/#performance-considerations","title":"Performance Considerations","text":"<ol> <li> <p>Body Inspection: Filters that set <code>needs_body() = True</code> will read the entire request/response body into memory. Use sparingly for large payloads.</p> </li> <li> <p>Filter Order: Place cheaper filters (header-based) before expensive ones (body-based) to short-circuit early.</p> </li> <li> <p>Caching Strategy: </p> </li> <li>Use <code>SpecificationPolicy</code> for standard HTTP caching (faster, battle-tested)</li> <li> <p>Use <code>FilterPolicy</code> only when you need custom logic</p> </li> <li> <p>Memory Usage: FilterPolicy may consume more memory when inspecting bodies. Consider implementing size limits in your filters.</p> </li> </ol>"},{"location":"policies/#see-also","title":"See Also","text":"<ul> <li>RFC 9111: HTTP Caching</li> <li>Specification State Machine</li> <li>Storage Backends</li> <li>GraphQL Integration</li> </ul>"},{"location":"specification/","title":"HTTP Caching State Machine","text":"<p>Hishel provides a sans-I/O implementation of the HTTP caching specification (RFC 9111), allowing you to integrate RFC-compliant caching into any Python application\u2014whether client-side or server-side.</p> <p>The implementation uses an event-driven state machine that tells you exactly what to do next based on HTTP caching rules. You handle all I/O (network requests, storage operations), while the state machine ensures RFC 9111 compliance.</p>"},{"location":"specification/#quick-start","title":"Quick Start","text":"<pre><code>from hishel import (\n    # States\n    IdleClient,\n    CacheMiss,\n    FromCache,\n    NeedRevalidation,\n    NeedToBeUpdated,\n    StoreAndUse,\n    CouldNotBeStored,\n    InvalidateEntries,\n\n    # Configuration\n    CacheOptions,\n)\n\n# Create an idle state (starting point)\nstate = IdleClient(options=CacheOptions())  # Starting point for client caching\n\n# The state machine guides you through the caching logic\nnext_state = state.next(request, associated_entries=[])\n\n# Each state has a specific signature for its next() method\n# Type hints tell you exactly what parameters are needed\n</code></pre>"},{"location":"specification/#how-it-works","title":"How It Works","text":"<p>The state machine exposes RFC 9111 logic as a series of states and transitions. Each state represents a specific situation in the HTTP caching lifecycle:</p> <ol> <li>You provide: HTTP requests, responses, and cached data</li> <li>State machine decides: What action to take next</li> <li>You execute: The I/O operations (network, storage)</li> <li>State machine validates: Ensures RFC compliance</li> </ol> <p>This design allows you to build HTTP caches that are: - \u2705 Correct: Fully compliant with RFC 9111 - \u2705 Testable: Sans-I/O design enables easy testing - \u2705 Flexible: Works with any I/O library or framework - \u2705 Type-safe: Fully typed with clear state transitions</p>"},{"location":"specification/#state-transitions","title":"State Transitions","text":"<p>The state machine follows a clear flow through different states based on HTTP caching rules defined in RFC 9111. Here's the complete transition map:</p> <pre><code>graph TB\n  IdleClient[IdleClient&lt;br/&gt;Starting Point] --&gt;|No cache or&lt;br/&gt;uncacheable| CacheMiss[CacheMiss&lt;br/&gt;Forward to Origin]\n  IdleClient --&gt;|Fresh cache| FromCache[FromCache&lt;br/&gt;Use Cached Response]\n  IdleClient --&gt;|Stale cache| NeedRevalidation[NeedRevalidation&lt;br/&gt;Validate with Origin]\n\n  CacheMiss --&gt;|Response&lt;br/&gt;cacheable| StoreAndUse[StoreAndUse&lt;br/&gt;Store &amp; Return]\n  CacheMiss --&gt;|Response not&lt;br/&gt;cacheable| CouldNotBeStored[CouldNotBeStored&lt;br/&gt;Return without storing]\n\n  NeedRevalidation --&gt;|304 Not&lt;br/&gt;Modified| NeedToBeUpdated[NeedToBeUpdated&lt;br/&gt;Freshen Cache]\n  NeedRevalidation --&gt;|2xx/5xx&lt;br/&gt;Response| InvalidateEntries[InvalidateEntries&lt;br/&gt;Delete Old Cache]\n\n  InvalidateEntries --&gt; CacheMiss\n  NeedToBeUpdated --&gt; FromCache\n\n  FromCache -.-&gt;|Terminal| End1((End))\n  StoreAndUse -.-&gt;|Terminal| End2((End))\n  CouldNotBeStored -.-&gt;|Terminal| End3((End))\n\n  style IdleClient fill:#8a94a3,stroke:#6c757d,color:#fff\n  style FromCache fill:#7ba88a,stroke:#5d8a6f,color:#fff\n  style StoreAndUse fill:#7ba88a,stroke:#5d8a6f,color:#fff\n  style CouldNotBeStored fill:#c97a7a,stroke:#a86565,color:#fff\n  style NeedRevalidation fill:#c9a961,stroke:#a88b4f,color:#fff\n  style InvalidateEntries fill:#b89a7f,stroke:#9a7d66,color:#fff</code></pre> <p>Legend:</p> <ul> <li>Blue: Entry state (IdleClient)</li> <li>Green: Success states (FromCache, StoreAndUse)</li> <li>Red: Failure state (CouldNotBeStored)</li> <li>Yellow: Intermediate states requiring I/O</li> <li>Orange: Action states (InvalidateEntries)</li> </ul>"},{"location":"specification/#state-flow-examples","title":"State Flow Examples","text":""},{"location":"specification/#example-1-fresh-cache-hit","title":"Example 1: Fresh Cache Hit","text":"<p><pre><code>Request \u2192 IdleClient \u2192 FromCache \u2192 End\n</code></pre> Scenario: Client requests <code>/api/users</code>, cache has fresh response Actions: Return cached response immediately, no origin contact</p>"},{"location":"specification/#example-2-cache-miss-and-store","title":"Example 2: Cache Miss and Store","text":"<p><pre><code>Request \u2192 IdleClient \u2192 CacheMiss \u2192 StoreAndUse \u2192 End\n</code></pre> Scenario: First request for <code>/api/products</code> Actions: Forward to origin, receive cacheable response, store it, return to client</p>"},{"location":"specification/#example-3-cache-miss-but-cannot-store","title":"Example 3: Cache Miss but Cannot Store","text":"<p><pre><code>Request \u2192 IdleClient \u2192 CacheMiss \u2192 CouldNotBeStored \u2192 End\n</code></pre> Scenario: Request <code>/api/private</code> with Authorization header, response has no cache directives Actions: Forward to origin, receive response with <code>no-store</code>, return without caching</p>"},{"location":"specification/#example-4-successful-revalidation-304","title":"Example 4: Successful Revalidation (304)","text":"<p><pre><code>Request \u2192 IdleClient \u2192 NeedRevalidation \u2192 NeedToBeUpdated \u2192 FromCache \u2192 End\n</code></pre> Scenario: Cached <code>/api/data</code> is stale, origin confirms it's unchanged Actions: Send conditional request, receive 304, update cache metadata, return cached content</p>"},{"location":"specification/#example-5-failed-revalidation-200","title":"Example 5: Failed Revalidation (200)","text":"<p><pre><code>Request \u2192 IdleClient \u2192 NeedRevalidation \u2192 InvalidateEntries \u2192 CacheMiss \u2192 StoreAndUse \u2192 End\n</code></pre> Scenario: Cached <code>/api/status</code> is stale, origin returns new content Actions: Send conditional request, receive 200 with new content, delete old cache, store new response</p> <pre><code>from hishel import IdleClient, CacheOptions\n\nstate = IdleClient(options=CacheOptions())  # Starting point for client caching\n\n# signature will look like:\n#   (method) def next(\n#       request: Request,\n#       associated_entries: list[Entry]\n#  )  -&gt; (CacheMiss | FromCache | NeedRevalidation)\nnext_state = state.next(...)\n</code></pre> <p>In this example, <code>next_state</code> will be one of <code>CacheMiss</code>, <code>FromCache</code>, or <code>NeedRevalidation</code>, each exposing the appropriate signature for its next method.</p>"},{"location":"specification/#states","title":"States","text":"<p>The state machine implements RFC 9111 through a series of well-defined states. Each state represents a specific point in the HTTP caching lifecycle and determines the next action to take.</p>"},{"location":"specification/#idleclient","title":"IdleClient","text":"<p>What it means: The starting point of the cache state machine. This state represents an idle client that has received a request and needs to determine whether it can be satisfied from cache, needs revalidation, or must be forwarded to the origin server.</p> <p>When you're in this state: </p> <ul> <li>A new HTTP request has been received</li> <li>You need to check if cached responses exist</li> <li>You need to evaluate if cached responses can be used</li> </ul> <p>Transitions:</p> <ul> <li>\u2192 FromCache: A fresh cached response exists and can be used immediately without contacting the origin server</li> <li>\u2192 NeedRevalidation: A stale cached response exists that requires validation with the origin server before use</li> <li>\u2192 CacheMiss: No suitable cached response exists, or the request cannot be satisfied from cache</li> </ul> <p>RFC Reference: Section 4 - Constructing Responses from Caches</p> <p>Example: <pre><code>from hishel import IdleClient, CacheOptions\n\n# Create idle state\nidle = IdleClient(options=CacheOptions())\n\n# Transition based on request and cached entries\nnext_state = idle.next(request, associated_entries=[])\n# Returns: CacheMiss | FromCache | NeedRevalidation\n</code></pre></p>"},{"location":"specification/#cachemiss","title":"CacheMiss","text":"<p>What it means: The request cannot be satisfied from cache and must be forwarded to the origin server. After receiving the origin's response, this state evaluates whether the response can be stored in the cache.</p> <p>When you're in this state:</p> <ul> <li>No suitable cached response exists for the request</li> <li>You've received a response from the origin server</li> <li>You need to determine if this response should be cached</li> </ul> <p>Transitions:</p> <ul> <li>\u2192 StoreAndUse: The response meets all RFC 9111 storage requirements and should be cached</li> <li>\u2192 CouldNotBeStored: The response fails one or more storage requirements and cannot be cached</li> </ul> <p>Storage Requirements Checked:</p> <ol> <li>Request method is understood by the cache</li> <li>Response status code is final (not 1xx)</li> <li>Cache understands the response status code</li> <li>No <code>no-store</code> directive present</li> <li><code>private</code> directive allows storage (for shared caches)</li> <li><code>Authorization</code> header is properly handled</li> <li>Response contains explicit caching information OR is heuristically cacheable</li> </ol> <p>RFC Reference: Section 3 - Storing Responses in Caches</p> <p>Example: <pre><code>from hishel import CacheMiss\n\n# After forwarding request to origin\ncache_miss = CacheMiss(request=request, options=options)\n\n# Evaluate response for storage\nnext_state = cache_miss.next(response)\n# Returns: StoreAndUse | CouldNotBeStored\n</code></pre></p>"},{"location":"specification/#needrevalidation","title":"NeedRevalidation","text":"<p>What it means: One or more stale cached responses exist for the request, but they cannot be used without validation. A conditional request must be sent to the origin server to check if the cached content is still valid.</p> <p>When you're in this state:</p> <ul> <li>Cached responses exist but are stale (past their freshness lifetime)</li> <li>The responses have validators (ETag or Last-Modified)</li> <li>You've sent a conditional request to the origin (If-None-Match or If-Modified-Since)</li> <li>You're waiting for the validation response</li> </ul> <p>Transitions:</p> <ul> <li>\u2192 NeedToBeUpdated: Origin responds with 304 Not Modified - cached responses are still valid and can be freshened</li> <li>\u2192 InvalidateEntries + CacheMiss: Origin responds with 2xx/5xx - cached responses are outdated and must be replaced</li> <li>\u2192 CacheMiss: No matching responses found during the freshening process</li> </ul> <p>Validation Process:</p> <ol> <li>Client sends conditional request with validators from cached response</li> <li>Origin server checks if content has changed</li> <li>304 response: Content unchanged, update cache metadata</li> <li>2xx/5xx response: Content changed or error, invalidate old cache and store new response</li> </ol> <p>RFC Reference: Section 4.3 - Validation</p> <p>Example: <pre><code>from hishel import NeedRevalidation\n\n# After detecting stale cache\nneed_revalidation = NeedRevalidation(\n    request=conditional_request,\n    original_request=original_request,\n    revalidating_entries=[stale_entry],\n    options=options\n)\n\n# Handle validation response\nnext_state = need_revalidation.next(validation_response)\n# Returns: NeedToBeUpdated | InvalidateEntries | CacheMiss\n</code></pre></p>"},{"location":"specification/#fromcache","title":"FromCache","text":"<p>What it means: A suitable cached response was found and can be used immediately to satisfy the request. No communication with the origin server is needed.</p> <p>When you're in this state: - A fresh cached response exists for the request - The cached response matches all request requirements (Vary headers, etc.) - The response is within its freshness lifetime OR stale responses are allowed</p> <p>Transitions:</p> <ul> <li>\u2192 None: This is a terminal state. Use the cached response to satisfy the request.</li> </ul> <p>What to do:</p> <ol> <li>Retrieve the cached response</li> <li>Update the Age header to reflect current age</li> <li>Return the response to the client</li> <li>No further state transitions needed</li> </ol> <p>RFC Reference: Section 4.2 - Freshness</p> <p>Example: <pre><code>from hishel import FromCache\n\n# When a fresh response is found\nfrom_cache = FromCache(entry=cached_entry, options=options)\n\n# This is a terminal state\nassert from_cache.next() is None\n\n# Use cached_entry.response to satisfy the request\n</code></pre></p>"},{"location":"specification/#needtobeupdated","title":"NeedToBeUpdated","text":"<p>What it means: The origin server responded with 304 Not Modified during revalidation. The cached responses are still valid but need their metadata refreshed with information from the 304 response.</p> <p>When you're in this state:</p> <ul> <li>You received a 304 Not Modified response</li> <li>One or more cached responses match the validators</li> <li>The cached content is still valid but metadata needs updating</li> </ul> <p>Transitions:</p> <ul> <li>\u2192 FromCache: After updating cached responses, use them to satisfy the request</li> </ul> <p>Update Process:</p> <ol> <li>Match cached responses using validators (ETag or Last-Modified)</li> <li>Update matched responses with new headers from 304 response</li> <li>Preserve the cached response body (content hasn't changed)</li> <li>Update freshness information (Date, Cache-Control, Expires)</li> </ol> <p>RFC Reference: Section 4.3.4 - Freshening Stored Responses</p> <p>Example: <pre><code>from hishel import NeedToBeUpdated\n\n# After 304 Not Modified\nneed_update = NeedToBeUpdated(\n    updating_entries=[cached_entry],\n    original_request=original_request,\n    options=options\n)\n\n# Transition to FromCache\nnext_state = need_update.next()\n# Returns: FromCache\n</code></pre></p>"},{"location":"specification/#storeanduse","title":"StoreAndUse","text":"<p>What it means: The response from the origin server meets all RFC 9111 storage requirements and should be saved to the cache. This is a terminal state indicating successful caching.</p> <p>When you're in this state:</p> <ul> <li>You received a response from the origin server</li> <li>The response passed all storage validation checks</li> <li>The response should be cached for future requests</li> </ul> <p>Transitions:</p> <ul> <li>\u2192 None: This is a terminal state. Store the response and use it to satisfy the request.</li> </ul> <p>What to do:</p> <ol> <li>Store the request-response entry in your cache storage</li> <li>Store any stream data (request/response bodies)</li> <li>Return the response to the client</li> <li>The response is now available for future requests</li> </ol> <p>RFC Reference: Section 3 - Storing Responses in Caches</p> <p>Example: <pre><code>from hishel import StoreAndUse\n\n# After determining response is cacheable\nstore_and_use = StoreAndUse(\n    entry_id=entry_id,\n    response=response,\n    options=options\n)\n\n# This is a terminal state\nassert store_and_use.next() is None\n\n# Store the entry and return the response\n</code></pre></p>"},{"location":"specification/#couldnotbestored","title":"CouldNotBeStored","text":"<p>What it means: The response from the origin server does not meet RFC 9111 storage requirements and cannot be cached. This is a terminal state indicating the response should be used but not stored.</p> <p>When you're in this state:</p> <ul> <li>You received a response from the origin server</li> <li>The response failed one or more storage validation checks</li> <li>The response should be returned to the client but not cached</li> </ul> <p>Common Reasons:</p> <ul> <li>Contains <code>no-store</code> cache directive</li> <li>Contains <code>private</code> directive (for shared caches)</li> <li>Method not supported for caching</li> <li>Status code not cacheable</li> <li><code>Authorization</code> header without explicit caching permission</li> <li>No explicit caching directives and not heuristically cacheable</li> </ul> <p>Transitions:</p> <ul> <li>\u2192 None: This is a terminal state. Use the response without storing it.</li> </ul> <p>What to do:</p> <ol> <li>Return the response to the client</li> <li>Do NOT store it in cache</li> <li>Future identical requests will also result in cache miss</li> </ol> <p>RFC Reference: Section 3 - Storing Responses in Caches</p> <p>Example: <pre><code>from hishel import CouldNotBeStored\n\n# After determining response is not cacheable\ncould_not_store = CouldNotBeStored(\n    response=response,\n    entry_id=entry_id,\n    options=options\n)\n\n# This is a terminal state\nassert could_not_store.next() is None\n\n# Return response without storing\n</code></pre></p>"},{"location":"specification/#invalidateentries","title":"InvalidateEntries","text":"<p>What it means: One or more cached response entries need to be invalidated (deleted) from the cache before proceeding to the next state. This is a wrapper state that performs cleanup before transitioning.</p> <p>When you're in this state:</p> <ul> <li>Outdated cached responses need to be removed</li> <li>You're proceeding to another state after cleanup</li> <li>This typically occurs during revalidation when new responses replace old ones</li> </ul> <p>Transitions:</p> <ul> <li>\u2192 next_state: After invalidating entries, transition to the wrapped next state (typically <code>CacheMiss</code> or <code>NeedToBeUpdated</code>)</li> </ul> <p>Common Scenarios:</p> <ol> <li>After 2xx response during revalidation: Old cached responses are outdated, invalidate them before storing new response</li> <li>After 5xx error during revalidation: Server error invalidates cached responses</li> <li>During freshening: Responses that don't match validators need removal</li> </ol> <p>What to do:</p> <ol> <li>Delete the specified entries from cache storage</li> <li>Delete associated stream data</li> <li>Transition to the next state specified</li> </ol> <p>Example: <pre><code>from hishel import InvalidateEntries, CacheMiss\n\n# During revalidation with new response\ninvalidate = InvalidateEntries(\n    entry_ids=[old_entry_id1, old_entry_id2],\n    next_state=CacheMiss(request=request, options=options),\n    options=options\n)\n\n# Get next state after invalidation\nnext_state = invalidate.next()\n# Returns: The wrapped next_state (e.g., CacheMiss)\n</code></pre></p>"},{"location":"specification/#configuration","title":"Configuration","text":"<p>You can pass an options parameter to any state to control how it behaves in certain situations. This was primarily added to allow configuration for cases where the RFC does not explicitly specify the behavior. In some places, the RFC might say that a cache MIGHT do something; the <code>options</code> parameter lets you define how to handle such cases.</p> <p>Import the CacheOptions class and pass it to the State, like so:</p> <pre><code>from hishel import IdleClient, CacheOptions\n\nstate = IdleClient(\n  options=CacheOptions(\n    allow_stale=True\n  )\n)\n</code></pre>"},{"location":"storages/","title":"Storage Backends","text":"<p>Hishel provides storage backends for persisting HTTP request-response pairs. These storages are designed to work with the RFC 9111-compliant state machine and support both synchronous and asynchronous operations.</p>"},{"location":"storages/#overview","title":"Overview","text":"<p>Storage backends handle:</p> <ul> <li>\u2705 Entry Management: Store complete request-response pairs (entries)</li> <li>\u2705 Stream Handling: Efficiently store and retrieve large response bodies</li> <li>\u2705 TTL Management: Automatic expiration and cleanup of old entries</li> <li>\u2705 Soft Deletion: Mark entries as deleted without immediate removal</li> <li>\u2705 Cache Keys: Group multiple entries under a single cache key</li> </ul>"},{"location":"storages/#available-storages","title":"Available Storages","text":"<p>Currently available: - SQLite Storage - Persistent storage using SQLite database (async and sync)</p> <p>Coming soon:</p> <ul> <li>Memory Storage - In-memory storage for testing and non-persistent caching</li> <li>any more...?</li> </ul>"},{"location":"storages/#sqlite-storage","title":"SQLite Storage","text":"<p>SQLite storage provides persistent, file-based caching with excellent performance characteristics. It uses two tables: one for request-response entries and another for streaming data chunks.</p>"},{"location":"storages/#initialization","title":"Initialization","text":"AsyncSync <pre><code>from hishel import AsyncSqliteStorage\n\n# Default configuration (creates hishel_cache.db in cache directory)\nstorage = AsyncSqliteStorage()\n\n# Custom database path\nstorage = AsyncSqliteStorage(database_path=\"my_cache.db\")\n\n# With TTL configuration\nstorage = AsyncSqliteStorage(\n    default_ttl=3600.0,  # 1 hour default TTL\n    refresh_ttl_on_access=True  # Reset TTL on access\n)\n\n# Custom connection (advanced usage)\nimport anysqlite\nconn = await anysqlite.connect(\"custom_cache.db\")\nstorage = AsyncSqliteStorage(connection=conn)\n</code></pre> <pre><code>from hishel import SyncSqliteStorage\n\n# Default configuration (creates hishel_cache.db in cache directory)\nstorage = SyncSqliteStorage()\n\n# Custom database path\nstorage = SyncSqliteStorage(database_path=\"my_cache.db\")\n\n# With TTL configuration\nstorage = SyncSqliteStorage(\n    default_ttl=3600.0,  # 1 hour default TTL\n    refresh_ttl_on_access=True  # Reset TTL on access\n)\n\n# Custom connection (advanced usage)\nimport sqlite3\nconn = sqlite3.connect(\"custom_cache.db\")\nstorage = SyncSqliteStorage(connection=conn)\n</code></pre>"},{"location":"storages/#configuration-options","title":"Configuration Options","text":"Parameter Type Default Description <code>connection</code> <code>Connection | None</code> <code>None</code> Pre-existing database connection. If <code>None</code>, a new connection is created. <code>database_path</code> <code>str</code> <code>\"hishel_cache.db\"</code> Path to the SQLite database file (relative to cache directory). <code>default_ttl</code> <code>float | None</code> <code>None</code> Default time-to-live in seconds for cached entries. <code>None</code> means no expiration. <code>refresh_ttl_on_access</code> <code>bool</code> <code>True</code> Whether to reset the TTL when an entry is accessed."},{"location":"storages/#basic-usage","title":"Basic Usage","text":""},{"location":"storages/#creating-entries","title":"Creating Entries","text":"<p>An \"entry\" consists of an HTTP request and its corresponding response. With the new API, you create a complete entry in one operation by providing both the request and response together.</p> AsyncSync <pre><code>from hishel import AsyncSqliteStorage, Request, Response, Headers\nfrom hishel._utils import make_async_iterator\n\nstorage = AsyncSqliteStorage()\n\n# Create a complete entry with request and response\nentry = await storage.create_entry(\n    request=Request(\n        method=\"GET\",\n        url=\"https://api.example.com/users\",\n        headers=Headers({\"User-Agent\": \"MyApp/1.0\"})\n    ),\n    response=Response(\n        status_code=200,\n        headers=Headers({\"Content-Type\": \"application/json\"}),\n        stream=make_async_iterator([b'{\"users\": []}'])\n    ),\n    key=\"GET:https://api.example.com/users\"  # Cache key\n)\n\n# Consume the response stream to save it\nasync for _ in entry.response.aiter_stream():\n    pass\n\n# entry has:\n# - id: UUID\n# - request: Request\n# - response: Response\n# - cache_key: bytes\n# - meta: EntryMeta (created_at timestamp)\n\nprint(f\"Created entry with ID: {entry.id}\")\nprint(f\"Response status: {entry.response.status_code}\")\n</code></pre> <pre><code>from hishel import SyncSqliteStorage, Request, Response, Headers\nfrom hishel._utils import make_iterator\n\nstorage = SyncSqliteStorage()\n\n# Create a complete entry with request and response\nentry = storage.create_entry(\n    request=Request(\n        method=\"GET\",\n        url=\"https://api.example.com/users\",\n        headers=Headers({\"User-Agent\": \"MyApp/1.0\"})\n    ),\n    response=Response(\n        status_code=200,\n        headers=Headers({\"Content-Type\": \"application/json\"}),\n        stream=make_iterator([b'{\"users\": []}'])\n    ),\n    key=\"GET:https://api.example.com/users\"  # Cache key\n)\n\n# Consume the response stream to save it\nfor _ in entry.response.iter_stream():\n    pass\n\n# entry has:\n# - id: UUID\n# - request: Request\n# - response: Response\n# - cache_key: bytes\n# - meta: EntryMeta (created_at timestamp)\n\nprint(f\"Created entry with ID: {entry.id}\")\nprint(f\"Response status: {entry.response.status_code}\")\n</code></pre>"},{"location":"storages/#custom-entry-ids","title":"Custom Entry IDs","text":"<p>You can optionally provide a custom UUID for the entry (useful for testing or specific use cases):</p> AsyncSync <pre><code>import uuid\n\nentry = await storage.create_entry(\n    request=request,\n    response=response,\n    key=\"my_cache_key\",\n    id_=uuid.UUID(int=0)  # Custom UUID\n)\n</code></pre> <pre><code>import uuid\n\nentry = storage.create_entry(\n    request=request,\n    response=response,\n    key=\"my_cache_key\",\n    id_=uuid.UUID(int=0)  # Custom UUID\n)\n</code></pre>"},{"location":"storages/#retrieving-cached-entries","title":"Retrieving Cached Entries","text":"<p>Retrieve all entries associated with a cache key.</p> AsyncSync <pre><code># Get all entries for a cache key\ncache_key = \"GET:https://api.example.com/users\"\nentries = await storage.get_entries(cache_key)\n\n# entries is a list of Entry objects\nfor entry in entries:\n    print(f\"Cached response: {entry.response.status_code}\")\n\n    # Access response body through stream\n    async for chunk in entry.response.aiter_stream():\n        print(f\"Response chunk: {chunk}\")\n</code></pre> <pre><code># Get all entries for a cache key\ncache_key = \"GET:https://api.example.com/users\"\nentries = storage.get_entries(cache_key)\n\n# entries is a list of Entry objects\nfor entry in entries:\n    print(f\"Cached response: {entry.response.status_code}\")\n\n    # Access response body through stream\n    for chunk in entry.response.iter_stream():\n        print(f\"Response chunk: {chunk}\")\n</code></pre>"},{"location":"storages/#updating-entries","title":"Updating Entries","text":"<p>Update an existing entry with new information.</p> AsyncSync <pre><code>import time\nfrom dataclasses import replace\n\n# Option 1: Update with a new entry object\nupdated_entry = replace(\n    entry,\n    meta=replace(entry.meta, created_at=time.time())\n)\nresult = await storage.update_entry(entry.id, updated_entry)\n\n# Option 2: Update using a callable\ndef update_cache_key(entry):\n    return replace(entry, cache_key=b\"new_key\")\n\nresult = await storage.update_entry(entry.id, update_cache_key)\n\nif result is None:\n    print(\"Entry not found\")\n</code></pre> <pre><code>from dataclasses import replace\n\n# Option 1: Update with a new entry object\nupdated_entry = replace(\n    entry,\n    response=replace(entry.response, status_code=304)\n)\nresult = storage.update_entry(entry.id, updated_entry)\n\n# Option 2: Update using a callable\ndef update_cache_key(entry):\n    return replace(entry, cache_key=b\"new_key\")\n\nresult = storage.update_entry(entry.id, update_cache_key)\n\nif result is None:\n    print(\"Entry not found\")\n</code></pre>"},{"location":"storages/#removing-entries","title":"Removing Entries","text":"<p>Remove entries from the cache (soft deletion - marked as deleted but not immediately removed).</p> AsyncSync <pre><code># Soft delete an entry\nawait storage.remove_entry(entry_id=entry.id)\n\n# The entry is marked as deleted and will be removed during cleanup\n</code></pre> <pre><code># Soft delete an entry\nstorage.remove_entry(entry_id=entry.id)\n\n# The entry is marked as deleted and will be removed during cleanup\n</code></pre>"},{"location":"storages/#complete-example","title":"Complete Example","text":"<p>Here's a complete example showing the full lifecycle of cache storage:</p> AsyncSync <pre><code>import uuid\nfrom hishel import AsyncSqliteStorage, Request, Response, Headers\nfrom hishel._utils import make_async_iterator\n\n# Initialize storage\nstorage = AsyncSqliteStorage(\n    database_path=\"my_app_cache.db\",\n    default_ttl=3600.0  # 1 hour\n)\n\n# Create cache key\ncache_key = \"GET:https://api.example.com/users\"\n\n# Step 1: Create a complete entry with request and response\nentry = await storage.create_entry(\n    request=Request(\n        method=\"GET\",\n        url=\"https://api.example.com/users\",\n        stream=make_async_iterator([b\"request body\"]),\n    ),\n    response=Response(\n        status_code=200,\n        headers=Headers({\"Content-Type\": \"application/json\"}),\n        stream=make_async_iterator([\n            b'{\"users\": [',\n            b'{\"id\": 1, \"name\": \"Alice\"},',\n            b'{\"id\": 2, \"name\": \"Bob\"}',\n            b']}',\n        ]),\n    ),\n    key=cache_key,\n)\n\n# Consume streams to store them\nasync for chunk in entry.request.aiter_stream():\n    pass  # Storage automatically saves chunks\n\nasync for chunk in entry.response.aiter_stream():\n    pass  # Storage automatically saves chunks\n\n# Step 2: Retrieve cached entries\ncached_entries = await storage.get_entries(cache_key)\n\nprint(f\"Found {len(cached_entries)} cached entry/entries\")\n\nfor entry in cached_entries:\n    print(f\"Request: {entry.request.method} {entry.request.url}\")\n    print(f\"Response: {entry.response.status_code}\")\n\n    # Read response body\n    body_chunks = []\n    async for chunk in entry.response.aiter_stream():\n        body_chunks.append(chunk)\n    body = b\"\".join(body_chunks)\n    print(f\"Body: {body.decode()}\")\n\n# Step 3: Update entry if needed\nfrom dataclasses import replace\n\nupdated_entry = replace(\n    entry,\n    cache_key=b\"updated_key\"\n)\nawait storage.update_entry(entry.id, updated_entry)\n\n# Step 4: Remove entry when no longer needed\nawait storage.remove_entry(entry.id)\n</code></pre> <pre><code>import uuid\nfrom hishel import SyncSqliteStorage, Request, Response, Headers\nfrom hishel._utils import make_iterator\n\n# Initialize storage\nstorage = SyncSqliteStorage(\n    database_path=\"my_app_cache.db\",\n    default_ttl=3600.0  # 1 hour\n)\n\n# Create cache key\ncache_key = \"GET:https://api.example.com/users\"\n\n# Step 1: Create a complete entry with request and response\nentry = storage.create_entry(\n    request=Request(\n        method=\"GET\",\n        url=\"https://api.example.com/users\",\n        stream=make_iterator([b\"request body\"]),\n    ),\n    response=Response(\n        status_code=200,\n        headers=Headers({\"Content-Type\": \"application/json\"}),\n        stream=make_iterator([\n            b'{\"users\": [',\n            b'{\"id\": 1, \"name\": \"Alice\"},',\n            b'{\"id\": 2, \"name\": \"Bob\"}',\n            b']}',\n        ]),\n    ),\n    key=cache_key,\n)\n\n# Consume streams to store them\nfor chunk in entry.request.iter_stream():\n    pass  # Storage automatically saves chunks\n\nfor chunk in entry.response.iter_stream():\n    pass  # Storage automatically saves chunks\n\n# Step 2: Retrieve cached entries\ncached_entries = storage.get_entries(cache_key)\n\nprint(f\"Found {len(cached_entries)} cached entry/entries\")\n\nfor entry in cached_entries:\n    print(f\"Request: {entry.request.method} {entry.request.url}\")\n    print(f\"Response: {entry.response.status_code}\")\n\n    # Read response body\n    body_chunks = []\n    for chunk in entry.response.iter_stream():\n        body_chunks.append(chunk)\n    body = b\"\".join(body_chunks)\n    print(f\"Body: {body.decode()}\")\n\n# Step 3: Update entry if needed\nfrom dataclasses import replace\n\nupdated_entry = replace(\n    entry,\n    cache_key=b\"updated_key\"\n)\nstorage.update_entry(entry.id, updated_entry)\n\n# Step 4: Remove entry when no longer needed\nstorage.remove_entry(entry.id)\n</code></pre>"},{"location":"storages/#advanced-topics","title":"Advanced Topics","text":""},{"location":"storages/#stream-handling","title":"Stream Handling","text":"<p>Hishel storages efficiently handle large request and response bodies using streams. Streams are automatically chunked and stored as you consume them.</p> <p>Important: You must consume streams (iterate through them) for the data to be stored. Simply creating an entry with a stream doesn't store the stream data.</p> AsyncSync <pre><code># Create entry with streaming body\nentry = await storage.create_entry(\n    request=Request(\n        method=\"POST\",\n        url=\"https://api.example.com/upload\",\n        stream=make_async_iterator([\n            b\"chunk1\",\n            b\"chunk2\",\n            b\"chunk3\",\n        ])\n    ),\n    response=Response(\n        status_code=200,\n        headers=Headers({}),\n        stream=make_async_iterator([b\"OK\"])\n    ),\n    key=cache_key\n)\n\n# IMPORTANT: Consume the streams to store them\nasync for chunk in entry.request.aiter_stream():\n    # Each chunk is stored as you iterate\n    pass\n\nasync for chunk in entry.response.aiter_stream():\n    pass\n\n# Now the streams are fully stored\n# You can retrieve them later:\nentries = await storage.get_entries(cache_key)\nasync for chunk in entries[0].request.aiter_stream():\n    print(f\"Chunk: {chunk}\")\n</code></pre> <pre><code># Create entry with streaming body\nentry = storage.create_entry(\n    request=Request(\n        method=\"POST\",\n        url=\"https://api.example.com/upload\",\n        stream=make_iterator([\n            b\"chunk1\",\n            b\"chunk2\",\n            b\"chunk3\",\n        ])\n    ),\n    response=Response(\n        status_code=200,\n        headers=Headers({}),\n        stream=make_iterator([b\"OK\"])\n    ),\n    key=cache_key\n)\n\n# IMPORTANT: Consume the streams to store them\nfor chunk in entry.request.iter_stream():\n    # Each chunk is stored as you iterate\n    pass\n\nfor chunk in entry.response.iter_stream():\n    pass\n\n# Now the streams are fully stored\n# You can retrieve them later:\nentries = storage.get_entries(cache_key)\nfor chunk in entries[0].request.iter_stream():\n    print(f\"Chunk: {chunk}\")\n</code></pre>"},{"location":"storages/#ttl-and-expiration","title":"TTL and Expiration","text":"<p>Control how long cached entries remain valid:</p> AsyncSync <pre><code># Set default TTL for all entries\nstorage = AsyncSqliteStorage(default_ttl=3600.0)  # 1 hour\n\n# Override TTL for specific requests using metadata\nentry = await storage.create_entry(\n    request=Request(\n        method=\"GET\",\n        url=\"https://api.example.com/data\",\n        metadata={\"hishel_ttl\": 7200.0}  # 2 hours for this entry\n    ),\n    response=response,\n    key=cache_key\n)\n\n# Disable TTL refresh on access\nstorage = AsyncSqliteStorage(\n    default_ttl=3600.0,\n    refresh_ttl_on_access=False  # TTL won't reset when accessed\n)\n</code></pre> <pre><code># Set default TTL for all entries\nstorage = SyncSqliteStorage(default_ttl=3600.0)  # 1 hour\n\n# Override TTL for specific requests using metadata\nentry = storage.create_entry(\n    request=Request(\n        method=\"GET\",\n        url=\"https://api.example.com/data\",\n        metadata={\"hishel_ttl\": 7200.0}  # 2 hours for this entry\n    ),\n    response=response,\n    key=cache_key\n)\n\n# Disable TTL refresh on access\nstorage = SyncSqliteStorage(\n    default_ttl=3600.0,\n    refresh_ttl_on_access=False  # TTL won't reset when accessed\n)\n</code></pre>"},{"location":"storages/#cleanup-and-maintenance","title":"Cleanup and Maintenance","text":"<p>Storage automatically performs cleanup operations to remove expired and deleted entries. Cleanup runs periodically when storage operations are performed.</p> <p>Cleanup removes:</p> <ul> <li>Expired entries (past their TTL)</li> <li>Entries marked as deleted for more than 7 days</li> <li>Entries with missing or incomplete streams</li> </ul> <p>The cleanup process is automatic and doesn't require manual intervention.</p>"},{"location":"storages/#custom-entry-ids_1","title":"Custom Entry IDs","text":"<p>By default, entry IDs are auto-generated UUIDs. You can provide custom IDs if needed:</p> AsyncSync <pre><code>import uuid\n\n# Provide custom UUID\ncustom_id = uuid.uuid4()\nentry = await storage.create_entry(\n    request=Request(method=\"GET\", url=\"https://api.example.com\"),\n    response=response,\n    key=cache_key,\n    id_=custom_id\n)\n\nassert entry.id == custom_id\n</code></pre> <pre><code>import uuid\n\n# Provide custom UUID\ncustom_id = uuid.uuid4()\nentry = storage.create_entry(\n    request=Request(method=\"GET\", url=\"https://api.example.com\"),\n    response=response,\n    key=cache_key,\n    id_=custom_id\n)\n\nassert entry.id == custom_id\n</code></pre>"},{"location":"storages/#database-schema","title":"Database Schema","text":"<p>For reference, here's the SQLite database schema used by the storage:</p>"},{"location":"storages/#entries-table","title":"<code>entries</code> Table","text":"<p>Stores request-response entry metadata.</p> Column Type Description <code>id</code> BLOB Primary key - UUID of the entry <code>cache_key</code> BLOB Cache key for grouping entries <code>data</code> BLOB Serialized entry data (request, response, metadata) <code>created_at</code> REAL Timestamp when the entry was created <code>deleted_at</code> REAL Timestamp when soft deleted (NULL if not deleted) <p>Indexes:</p> <ul> <li><code>idx_entries_cache_key</code> - Fast lookups by cache key</li> <li><code>idx_entries_deleted_at</code> - Efficient cleanup queries</li> </ul>"},{"location":"storages/#streams-table","title":"<code>streams</code> Table","text":"<p>Stores request and response body chunks.</p> Column Type Description <code>entry_id</code> BLOB Foreign key to entries.id <code>kind</code> INTEGER Stream type: 0 = request, 1 = response <code>chunk_number</code> INTEGER Chunk sequence number (0, 1, 2, ... or -1 for completion marker) <code>chunk_data</code> BLOB The actual chunk data <p>Primary Key: <code>(entry_id, kind, chunk_number)</code></p> <p>Special Values:</p> <ul> <li><code>chunk_number = -1</code> - Completion marker (empty data, signals end of stream)</li> <li><code>kind = 1</code> - Response stream</li> </ul>"},{"location":"integrations/asgi/","title":"ASGI Integration","text":"<p>Hishel provides ASGI middleware for caching HTTP responses in any ASGI-compatible application (FastAPI, Starlette, Django ASGI, etc.).</p> <p>The middleware intercepts requests and responses, caching them according to HTTP caching specifications (RFC 9111) or custom rules.</p>"},{"location":"integrations/asgi/#installation","title":"Installation","text":"<pre><code>pip install hishel\n</code></pre> <p>No extra dependencies required - ASGI support is included by default.</p>"},{"location":"integrations/asgi/#quick-start","title":"Quick Start","text":"<p>Wrap your ASGI application with <code>ASGICacheMiddleware</code>:</p> <pre><code>from hishel.asgi import ASGICacheMiddleware\n\n# Your ASGI application\nasync def app(scope, receive, send):\n    if scope[\"type\"] == \"http\":\n        await send({\n            \"type\": \"http.response.start\",\n            \"status\": 200,\n            \"headers\": [[b\"cache-control\", b\"max-age=3600\"]],\n        })\n        await send({\n            \"type\": \"http.response.body\",\n            \"body\": b\"Hello, World!\",\n        })\n\n# Wrap with caching middleware\ncached_app = ASGICacheMiddleware(app)\n</code></pre>"},{"location":"integrations/asgi/#basic-usage","title":"Basic Usage","text":""},{"location":"integrations/asgi/#http-caching-with-hishel","title":"HTTP Caching with Hishel","text":"<p>Hishel provides elegant HTTP caching middleware for ASGI applications.</p>"},{"location":"integrations/asgi/#installation_1","title":"Installation","text":"<pre><code>pip install hishel fastapi aiohttp litestar blacksheep uvicorn\n</code></pre>"},{"location":"integrations/asgi/#examples","title":"Examples","text":"FastAPILitestarBlackSheep <pre><code># fastapi_example.py\nfrom fastapi import FastAPI\nfrom hishel import ASGICacheMiddleware\n\napp = FastAPI()\n\n@app.get(\"/\")\nasync def index():\n    return {\"message\": \"Hello, world!\"}\n\napp = ASGICacheMiddleware(app)\n\n# Run: uvicorn fastapi_example:app --reload\n</code></pre> <pre><code># litestar_example.py\nfrom litestar import Litestar, get\nfrom hishel import ASGICacheMiddleware\n\n@get(\"/\")\nasync def index() -&gt; str:\n    return \"Hello, world!\"\n\napp = ASGICacheMiddleware(Litestar([index]))\n\n# Run: uvicorn litestar_example:app --reload\n</code></pre> <pre><code># blacksheep_example.py\nfrom blacksheep import Application, get\nfrom hishel import ASGICacheMiddleware\n\napp = Application()\n\n@get(\"/\")\nasync def index():\n    return \"Hello, world!\"\n\napp = ASGICacheMiddleware(app)\n\n# Run: uvicorn blacksheep_example:app --reload\n</code></pre>"},{"location":"integrations/asgi/#see-also","title":"See Also","text":"<ul> <li>Storage Backends - Configure cache storage</li> <li>Request/Response Metadata - Control caching behavior</li> <li>FastAPI Integration - FastAPI-specific helpers</li> </ul>"},{"location":"integrations/blacksheep/","title":"BlackSheep Integration","text":"<p>Hishel provides seamless integration with BlackSheep through ASGI middleware. You can use BlackSheep's built-in <code>cache_control</code> decorator to set Cache-Control headers, and combine it with Hishel's ASGI middleware for local server-side caching.</p> <p>Two approaches</p> <ul> <li>Use BlackSheep's <code>@cache_control()</code> decorator to send Cache-Control headers to clients (browsers, CDNs, proxies)</li> <li>Add Hishel's ASGI middleware to also cache responses locally based on those Cache-Control headers</li> </ul>"},{"location":"integrations/blacksheep/#installation","title":"Installation","text":"<pre><code>pip install hishel blacksheep\n</code></pre>"},{"location":"integrations/blacksheep/#quick-start","title":"Quick Start","text":""},{"location":"integrations/blacksheep/#cache-control-headers-only","title":"Cache-Control Headers Only","text":"<p>Use BlackSheep's built-in <code>cache_control</code> decorator:</p> <pre><code>from blacksheep import Application, get\nfrom blacksheep.server.headers.cache import cache_control\n\napp = Application()\n\n@get(\"/api/data\")\n@cache_control(max_age=300, public=True)\nasync def get_data():\n    # Cache-Control: public, max-age=300\n    return {\"data\": \"Clients will cache this for 5 minutes\"}\n</code></pre>"},{"location":"integrations/blacksheep/#with-local-server-caching","title":"With Local Server Caching","text":"<p>Combine BlackSheep's <code>cache_control</code> decorator with Hishel's ASGI middleware:</p> <pre><code>from blacksheep import Application, get\nfrom blacksheep.server.headers.cache import cache_control\nfrom hishel.asgi import ASGICacheMiddleware\nfrom hishel import AsyncSqliteStorage\n\napp = Application()\n\n@get(\"/api/data\")\n@cache_control(max_age=300, public=True)\nasync def get_data():\n    # Cached locally AND by clients/CDNs\n    return {\"data\": \"Expensive operation result\"}\n\n# Wrap with Hishel's ASGI middleware for local caching\napp = ASGICacheMiddleware(\n    app,\n    storage=AsyncSqliteStorage(),\n)\n</code></pre>"},{"location":"integrations/blacksheep/#common-examples","title":"Common Examples","text":""},{"location":"integrations/blacksheep/#static-assets","title":"Static Assets","text":"<p>Cache static files for a long time:</p> <pre><code>@get(\"/static/logo.png\")\n@cache_control(max_age=31536000, public=True, immutable=True)\nasync def get_logo():\n    return {\"file\": \"logo.png\"}\n</code></pre>"},{"location":"integrations/blacksheep/#public-api-data","title":"Public API Data","text":"<p>Cache public API responses:</p> <pre><code>@get(\"/api/articles\")\n@cache_control(max_age=300, public=True)\nasync def get_articles():\n    return {\"articles\": [\"Article 1\", \"Article 2\"]}\n</code></pre>"},{"location":"integrations/blacksheep/#private-user-data","title":"Private User Data","text":"<p>Cache user-specific data (browsers only):</p> <pre><code>@get(\"/api/user/profile\")\n@cache_control(max_age=300, private=True)\nasync def get_profile():\n    return {\"user\": \"john_doe\"}\n</code></pre>"},{"location":"integrations/blacksheep/#cdn-optimization","title":"CDN Optimization","text":"<p>Different cache times for browsers vs CDNs:</p> <pre><code>@get(\"/api/data\")\n@cache_control(max_age=60, s_maxage=3600, public=True)\nasync def get_data():\n    # Browsers: 1 minute, CDN: 1 hour\n    return {\"data\": \"...\"}\n</code></pre>"},{"location":"integrations/blacksheep/#no-caching","title":"No Caching","text":"<p>Prevent caching of sensitive data:</p> <pre><code>@get(\"/api/secrets\")\n@cache_control(no_cache=True, no_store=True)\nasync def get_secrets():\n    # Cache-Control: no-cache, no-store\n    return {\"secret\": \"This response should not be cached or stored!\"}\n</code></pre>"},{"location":"integrations/blacksheep/#how-it-works","title":"How It Works","text":"<ol> <li>BlackSheep's <code>@cache_control()</code> decorator adds Cache-Control headers to responses</li> <li>Hishel's ASGI middleware reads those headers and caches responses locally according to RFC 9111</li> <li>Subsequent requests are served from the local cache when valid, or forwarded to your handlers when cache is stale/missing</li> </ol> <p>This gives you the best of both worlds: - \u2705 Client-side caching (browsers, CDNs) via Cache-Control headers - \u2705 Server-side caching to reduce load on your application - \u2705 RFC 9111 compliant caching behavior - \u2705 Simple, declarative API using BlackSheep's native decorators</p>"},{"location":"integrations/blacksheep/#notes","title":"Notes","text":"<p>Use BlackSheep's native decorator</p> <p>BlackSheep has excellent built-in cache control support. Use <code>@cache_control()</code> from BlackSheep rather than creating custom headers.</p> <p>no_store is strongest</p> <p><code>no_store</code> prevents all caching regardless of other directives.</p>"},{"location":"integrations/blacksheep/#see-also","title":"See Also","text":"<ul> <li>ASGI Integration - General ASGI middleware documentation</li> <li>FastAPI Integration - Similar integration with FastAPI</li> <li>Storage Backends - Configure cache storage</li> <li>BlackSheep Documentation</li> <li>RFC 9111: HTTP Caching</li> </ul>"},{"location":"integrations/custom/","title":"Custom Integrations","text":"<p>Hishel is designed to be flexible and easy to integrate with any HTTP client or server. This guide will help you build custom integrations for libraries that aren't yet supported out of the box.</p>"},{"location":"integrations/custom/#converting-requestresponse-models","title":"Converting Request/Response Models","text":"<p>The core of any Hishel integration is converting your library's request/response models to Hishel's internal <code>Request</code> and <code>Response</code> models. This translation layer allows Hishel to cache responses regardless of which HTTP library you're using.</p> <p>In the Hishel codebase, you'll find conversion methods like <code>httpx_to_internal</code>, <code>requests_to_internal</code>, etc. that handle popular libraries. You can use these as reference implementations when building your own integration.</p>"},{"location":"integrations/custom/#core-conversion-principles","title":"Core Conversion Principles","text":"<p>Follow these guidelines when converting models:</p> <p>Response Content : The response content should be the actual data, possibly compressed, but decoded if it was sent with transfer encoding (like chunked). This content must be reusable\u2014if you store compressed data, also preserve the <code>Content-Encoding</code> header so it can be decoded later.</p> <p>Headers : Store headers as-is, except for headers that the HTTP specification doesn't allow caching. Important: If a response stream has already been consumed and decoded into memory before reaching the cache layer, you must remove the <code>Content-Encoding</code> header since the content is no longer encoded.</p> <p>Requests : Converting request models is simpler than responses. Hishel doesn't recreate requests from cache or store request body streams\u2014only headers, method, and URL are needed. The converted request may be modified by Hishel before being sent to the server, but exact preservation of the request body isn't critical.</p>"},{"location":"integrations/custom/#using-cache-proxy-classes","title":"Using Cache Proxy Classes","text":"<p>Hishel provides <code>AsyncCacheProxy</code> and <code>SyncCacheProxy</code> helper classes that handle all the caching logic for you. These classes are independent of any specific HTTP library and work only with Hishel's internal models, making them perfect for building new integrations.</p>"},{"location":"integrations/custom/#asynccacheproxy","title":"AsyncCacheProxy","text":"<p>The <code>AsyncCacheProxy</code> class manages the entire HTTP caching state machine. You simply provide it with a function that sends requests, and it handles:</p> <ul> <li>Cache key generation</li> <li>Storage operations</li> <li>RFC 9111 compliance</li> <li>State machine transitions</li> <li>TTL management</li> </ul> <p>Basic Usage:</p> <pre><code>from hishel import AsyncCacheProxy, AsyncSqliteStorage, CacheOptions, SpecificationPolicy\n\nasync def send_request(request: Request) -&gt; Response:\n    # Your code to send the HTTP request\n    # This is where you convert from internal models to your library\n    # and back\n    pass\n\n# Create the cache proxy\ncache_proxy = AsyncCacheProxy(\n    request_sender=send_request,\n    storage=AsyncSqliteStorage(),  # Optional, defaults to AsyncSqliteStorage\n    policy=SpecificationPolicy(),   # Optional, defaults to SpecificationPolicy()\n)\n\n# Handle a request with caching\nresponse = await cache_proxy.handle_request(request)\n</code></pre> <p>Key Features:</p> <ul> <li>Automatic cache key generation: Based on URL and optional request body hashing</li> <li>Spec-compliant caching: Full RFC 9111 state machine handling</li> <li>Spec-ignoring mode: Simple cache lookup without RFC 9111 rules</li> <li>TTL refresh: Automatic TTL updates on cache access if configured</li> <li>Vary header support: Proper handling of content negotiation</li> </ul>"},{"location":"integrations/custom/#synccacheproxy","title":"SyncCacheProxy","text":"<p>The synchronous version works identically but for blocking I/O:</p> <pre><code>from hishel import SyncCacheProxy, SyncSqliteStorage, SpecificationPolicy\n\ndef send_request(request: Request) -&gt; Response:\n    # Your synchronous request sending code\n    pass\n\ncache_proxy = SyncCacheProxy(\n    request_sender=send_request,\n    storage=SyncSqliteStorage(),\n    policy=SpecificationPolicy(),\n)\n\nresponse = cache_proxy.handle_request(request)\n</code></pre>"},{"location":"integrations/custom/#integration-example-httpx","title":"Integration Example: httpx","text":"<p>Here's how the httpx integration uses <code>AsyncCacheProxy</code>:</p> <pre><code>from hishel import AsyncCacheProxy, Request, Response\nimport httpx\n\nclass AsyncCacheTransport(httpx.AsyncBaseTransport):\n    def __init__(\n        self,\n        next_transport: httpx.AsyncBaseTransport,\n        storage: AsyncBaseStorage | None = None,\n        cache_options: CacheOptions | None = None,\n    ):\n        self._transport = next_transport\n\n        # Define how to send a request using the underlying transport\n        async def send_request(internal_request: Request) -&gt; Response:\n            # Convert internal Request to httpx.Request\n            httpx_request = internal_to_httpx(internal_request)\n\n            # Send using underlying transport\n            httpx_response = await self._transport.handle_async_request(httpx_request)\n\n            # Convert httpx.Response to internal Response\n            return httpx_to_internal(httpx_response)\n\n        # Create the cache proxy with our send function\n        self._cache_proxy = AsyncCacheProxy(\n            request_sender=send_request,\n            storage=storage,\n            cache_options=cache_options,\n        )\n\n    async def handle_async_request(self, request: httpx.Request) -&gt; httpx.Response:\n        # Convert httpx.Request to internal Request\n        internal_request = httpx_to_internal(request)\n\n        # Let the cache proxy handle the request\n        internal_response = await self._cache_proxy.handle_request(internal_request)\n\n        # Convert internal Response back to httpx.Response\n        return internal_to_httpx(internal_response)\n</code></pre>"},{"location":"integrations/custom/#when-to-use-cache-proxy-classes","title":"When to Use Cache Proxy Classes","text":"<p>Use <code>AsyncCacheProxy</code>/<code>SyncCacheProxy</code> when:</p> <ul> <li>\u2705 Building a new integration from scratch</li> <li>\u2705 You want automatic RFC 9111 compliance</li> <li>\u2705 You need both spec-respecting and spec-ignoring modes</li> <li>\u2705 You want to focus on model conversion, not caching logic</li> </ul>"},{"location":"integrations/custom/#configuration-options","title":"Configuration Options","text":"<p>Both proxy classes accept these parameters:</p> Parameter Type Default Description <code>request_sender</code> <code>Callable</code> Required Function that sends requests using your HTTP library <code>storage</code> <code>AsyncBaseStorage</code> / <code>SyncBaseStorage</code> <code>AsyncSqliteStorage()</code> / <code>SyncSqliteStorage()</code> Where to store cached responses <code>policy</code> <code>CachePolicy</code> <code>SpecificationPolicy()</code> Caching policy to use"},{"location":"integrations/custom/#implementation-example","title":"Implementation Example","text":"<p>Here's how to translate synchronous httpx Request/Response models to Hishel's internal models:</p> <pre><code>import httpx\nfrom typing import Iterator, Union, cast, overload\nfrom hishel.models import Request, Response, RequestMetadata, Headers\nfrom hishel.utils import filter_mapping, make_sync_iterator\n\n# 128 KB\nCHUNK_SIZE = 131072\n\n\n@overload\ndef httpx_to_internal(value: httpx.Request) -&gt; Request: ...\n@overload\ndef httpx_to_internal(value: httpx.Response) -&gt; Response: ...\ndef httpx_to_internal(\n    value: Union[httpx.Request, httpx.Response],\n) -&gt; Union[Request, Response]:\n    \"\"\"\n    Convert httpx.Request/httpx.Response to internal Request/Response.\n    \"\"\"\n    headers = Headers(\n        filter_mapping(\n            Headers({key: value for key, value in value.headers.items()}),\n            [\"Transfer-Encoding\"],\n        )\n    )\n    if isinstance(value, httpx.Request):\n        extension_metadata = RequestMetadata(\n            hishel_refresh_ttl_on_access=value.extensions.get(\"hishel_refresh_ttl_on_access\"),\n            hishel_ttl=value.extensions.get(\"hishel_ttl\"),\n            hishel_body_key=value.extensions.get(\"hishel_body_key\"),\n        )\n        headers_metadata = extract_metadata_from_headers(value.headers)\n\n        for key, val in extension_metadata.items():\n            if key in value.extensions:\n                headers_metadata[key] = val\n\n        return Request(\n            method=value.method,\n            url=str(value.url),\n            headers=headers,\n            stream=cast(Iterator[bytes], value.stream),\n            metadata=headers_metadata,\n        )\n    elif isinstance(value, httpx.Response):\n        stream = (\n            make_sync_iterator([value.content]) if value.is_stream_consumed else value.iter_raw(chunk_size=CHUNK_SIZE)\n        )\n\n        return Response(\n            status_code=value.status_code,\n            headers=headers,\n            stream=stream,\n            metadata={},\n        )\n</code></pre> <p>Critical: Stream Must Be Available</p> <p>If a stream was consumed without being read into memory, there's no way to access the data. Hishel will raise an error in this case to prevent silent data loss.</p>"},{"location":"integrations/custom/#common-pitfalls-and-solutions","title":"Common Pitfalls and Solutions","text":""},{"location":"integrations/custom/#stream-consumption","title":"Stream Consumption","text":"<p>Always ensure consumed streams are stored in memory before conversion. Check your library's documentation for methods like <code>is_stream_consumed</code> or <code>content</code> that indicate whether data is still available.</p> <p>Best Practice: Read the stream into memory before creating the Hishel Response: <pre><code># Good: Stream is preserved\nif response.is_stream_consumed:\n    stream = make_iterator([response.content])\nelse:\n    stream = response.iter_raw()\n\n# Bad: Stream was consumed elsewhere without storing\n# This will fail when Hishel tries to cache\n</code></pre></p>"},{"location":"integrations/custom/#header-filtering","title":"Header Filtering","text":"<p>Which Headers to Remove</p> <p>Remove these headers when caching responses:</p> <p>Hop-by-hop headers (never cached):</p> <ul> <li><code>Connection</code></li> <li><code>Keep-Alive</code></li> <li><code>Proxy-Authenticate</code></li> <li><code>Proxy-Authorization</code></li> <li><code>TE</code></li> <li><code>Trailers</code></li> <li><code>Transfer-Encoding</code></li> <li><code>Upgrade</code></li> </ul> <p>Encoding headers (remove only if content is decoded):</p> <ul> <li><code>Content-Encoding</code> - Remove when you've decoded the content</li> </ul>"},{"location":"integrations/custom/#testing-your-integration","title":"Testing Your Integration","text":"<p>When implementing a custom integration, test these scenarios:</p> <ol> <li>Basic caching flow - Request \u2192 Response \u2192 Cache \u2192 Retrieve</li> <li>Compressed responses - gzip, deflate, brotli</li> <li>Chunked transfer encoding - Verify proper handling</li> <li>Stream states - Both consumed and unconsumed streams</li> <li>HTTP status codes - 200, 304, 404, 500, etc.</li> <li>Content types - JSON, HTML, binary data, large files</li> <li>Request metadata - Custom Hishel extensions and TTL settings</li> </ol>"},{"location":"integrations/custom/#example-test-case","title":"Example Test Case","text":"<pre><code>def test_basic_caching():\n    # Create a request\n    request = mylib.Request(\"GET\", \"https://example.com\")\n\n    # Convert to internal model\n    internal_request = mylib_to_internal(request)\n\n    # Verify conversion\n    assert internal_request.method == \"GET\"\n    assert internal_request.url == \"https://example.com\"\n    assert \"Transfer-Encoding\" not in internal_request.headers\n</code></pre>"},{"location":"integrations/custom/#integration-template","title":"Integration Template","text":"<p>Here's a template to get started with integrating a new library:</p> <pre><code>from typing import Union, overload\nfrom hishel.models import Request, Response, Headers, RequestMetadata\n\n@overload\ndef mylib_to_internal(value: MyLibRequest) -&gt; Request: ...\n\n@overload\ndef mylib_to_internal(value: MyLibResponse) -&gt; Response: ...\n\ndef mylib_to_internal(\n    value: Union[MyLibRequest, MyLibResponse],\n) -&gt; Union[Request, Response]:\n    \"\"\"Convert MyLib models to Hishel internal models.\"\"\"\n\n    if isinstance(value, MyLibRequest):\n        # Extract method, URL, and headers\n        method = value.method\n        url = str(value.url)\n        headers = Headers({k: v for k, v in value.headers.items()})\n\n        # Create request stream if body exists\n        stream = value.stream if hasattr(value, 'stream') else iter([])\n\n        # Extract Hishel metadata from extensions/extras if available\n        metadata = {}\n        if hasattr(value, 'extensions'):\n            metadata = {\n                'hishel_ttl': value.extensions.get('hishel_ttl'),\n                # Add other metadata as needed\n            }\n\n        return Request(\n            method=method,\n            url=url,\n            headers=headers,\n            stream=stream,\n            metadata=metadata,\n        )\n\n    elif isinstance(value, MyLibResponse):\n        # Extract status code\n        status_code = value.status_code\n\n        # Filter headers (remove hop-by-hop and encoding headers if needed)\n        headers = Headers({k: v for k, v in value.headers.items()})\n        # Remove Transfer-Encoding\n        headers = filter_headers(headers, [\"Transfer-Encoding\"])\n\n        # Handle stream consumption state\n        if value.is_consumed:\n            # Stream was consumed, use stored content\n            stream = make_iterator([value.content])\n            # Remove Content-Encoding if content was decoded\n            headers = filter_headers(headers, [\"Content-Encoding\"])\n        else:\n            # Stream still available\n            stream = value.iter_content(chunk_size=131072)\n\n        return Response(\n            status_code=status_code,\n            headers=headers,\n            stream=stream,\n            metadata={},\n        )\n</code></pre>"},{"location":"integrations/custom/#need-help","title":"Need Help?","text":"<p>If you're building an integration and encounter issues:</p> <ol> <li>Check existing integrations - Look at httpx, requests, and aiohttp implementations in the Hishel codebase</li> <li>Open an issue - Post your use case on GitHub Issues</li> <li>Contribute back - Consider contributing your integration to help others!</li> </ol>"},{"location":"integrations/custom/#related-documentation","title":"Related Documentation","text":"<ul> <li>ASGI Integration - Full ASGI middleware for caching</li> <li>HTTPX Integration - Async HTTP client with caching</li> <li>Requests Integration - Synchronous HTTP client with caching</li> </ul>"},{"location":"integrations/fastapi/","title":"FastAPI Integration","text":"<p>Hishel provides FastAPI integration in two ways:</p> <ol> <li>Cache-Control Headers Only - Use the <code>cache()</code> dependency to send proper Cache-Control headers to clients (browsers, CDNs, proxies)</li> <li>Full Caching - Combine with ASGI middleware to also cache responses locally based on the Cache-Control rules you specify</li> </ol> <p>Choose your approach</p> <ul> <li>Use <code>cache()</code> dependency alone to let clients/CDNs cache responses</li> <li>Add ASGI middleware on top to also cache locally on your server</li> <li>Both approaches use the same Cache-Control headers for consistency</li> </ul>"},{"location":"integrations/fastapi/#installation","title":"Installation","text":"<pre><code>pip install hishel[fastapi]\n</code></pre> <p>Or if you already have FastAPI installed:</p> <pre><code>pip install hishel\n</code></pre>"},{"location":"integrations/fastapi/#quick-start","title":"Quick Start","text":""},{"location":"integrations/fastapi/#cache-control-headers-only","title":"Cache-Control Headers Only","text":"<p>Use the <code>cache()</code> dependency to add Cache-Control headers:</p> <pre><code>from fastapi import FastAPI\nfrom hishel.fastapi import cache\n\napp = FastAPI()\n\n@app.get(\"/api/data\", dependencies=[cache(max_age=300, public=True)])\nasync def get_data():\n    # Cache-Control: public, max-age=300\n    return {\"data\": \"Clients will cache this for 5 minutes\"}\n</code></pre>"},{"location":"integrations/fastapi/#with-local-server-caching","title":"With Local Server Caching","text":"<p>Combine with ASGI middleware to also cache locally:</p> <pre><code>from fastapi import FastAPI\nfrom hishel.fastapi import cache\nfrom hishel.asgi import ASGICacheMiddleware\nfrom hishel import AsyncSqliteStorage\n\napp = FastAPI()\n\n@app.get(\"/api/data\", dependencies=[cache(max_age=300, public=True)])\nasync def get_data():\n    # Cached locally AND by clients/CDNs\n    return {\"data\": \"Expensive operation result\"}\n\n# Wrap with caching middleware to enable local caching\napp = ASGICacheMiddleware(\n    app,\n    storage=AsyncSqliteStorage(),\n)\n</code></pre>"},{"location":"integrations/fastapi/#common-examples","title":"Common Examples","text":""},{"location":"integrations/fastapi/#static-assets","title":"Static Assets","text":"<p>Cache static files for a long time:</p> <pre><code>@app.get(\"/static/logo.png\", dependencies=[cache(max_age=31536000, public=True, immutable=True)])\nasync def get_logo():\n    return {\"file\": \"logo.png\"}\n</code></pre>"},{"location":"integrations/fastapi/#public-api-data","title":"Public API Data","text":"<p>Cache public API responses:</p> <pre><code>@app.get(\"/api/articles\", dependencies=[cache(max_age=300, public=True)])\nasync def get_articles():\n    return {\"articles\": [...]}\n</code></pre>"},{"location":"integrations/fastapi/#private-user-data","title":"Private User Data","text":"<p>Cache user-specific data (browsers only):</p> <pre><code>@app.get(\"/api/user/profile\", dependencies=[cache(max_age=300, private=True)])\nasync def get_profile():\n    return {\"user\": \"john_doe\"}\n</code></pre>"},{"location":"integrations/fastapi/#cdn-optimization","title":"CDN Optimization","text":"<p>Different cache times for browsers vs CDNs:</p> <pre><code>@app.get(\"/api/data\", dependencies=[cache(\n    max_age=60,      # Browsers: 1 minute\n    s_maxage=3600,   # CDN: 1 hour\n    public=True\n)])\nasync def get_data():\n    return {\"data\": \"...\"}\n</code></pre>"},{"location":"integrations/fastapi/#no-caching","title":"No Caching","text":"<p>Prevent caching of sensitive data:</p> <pre><code>@app.get(\"/api/secrets\", dependencies=[cache(no_store=True)])\nasync def get_secrets():\n    return {\"secret\": \"value\"}\n</code></pre>"},{"location":"integrations/fastapi/#notes","title":"Notes","text":"<p>Combine directives wisely</p> <p>Some directives conflict (e.g., <code>public</code> and <code>private</code>). Choose combinations that match your caching strategy.</p> <p>no_store is strongest</p> <p><code>no_store</code> prevents all caching regardless of other directives.</p> <p>Field names for fine-grained control</p> <p><code>private</code> and <code>no_cache</code> accept lists of header names for precise control over which parts of the response require special handling.</p>"},{"location":"integrations/fastapi/#see-also","title":"See Also","text":"<ul> <li>ASGI Integration - Full ASGI middleware for caching</li> <li>Request/Response Metadata - Control caching behavior</li> <li>Storage Backends - Configure cache storage</li> <li>RFC 9111: HTTP Caching</li> <li>RFC 8246: Immutable Responses</li> <li>RFC 5861: Cache-Control Extensions</li> </ul>"},{"location":"integrations/graphql/","title":"GraphQL Integration","text":"<p>Hishel provides robust support for caching GraphQL queries through body-sensitive content caching. Since GraphQL typically uses POST requests with different query bodies to the same endpoint, standard URL-based caching won't work. Hishel solves this by including the request body in the cache key.</p>"},{"location":"integrations/graphql/#why-body-sensitive-caching","title":"Why Body-Sensitive Caching?","text":"<p>Traditional HTTP caching uses the URL as the cache key. However, GraphQL APIs typically:</p> <ul> <li>Use a single endpoint (e.g., <code>/graphql</code>)</li> <li>Send queries via POST requests with JSON bodies</li> <li>Have different queries/mutations that need separate cache entries</li> </ul> <p>Hishel's body-sensitive caching creates unique cache keys based on the request body, allowing proper caching of GraphQL queries.</p>"},{"location":"integrations/graphql/#quick-start","title":"Quick Start","text":""},{"location":"integrations/graphql/#per-request-configuration","title":"Per-Request Configuration","text":"<p>Enable body-based caching for specific GraphQL requests using the <code>X-Hishel-Body-Key</code> header:</p> <pre><code>from hishel.httpx import SyncCacheClient\n\nclient = SyncCacheClient()\n\nquery = \"\"\"\n    query GetUser($userId: ID!) {\n        user(id: $userId) {\n            id\n            name\n            email\n            avatar\n        }\n    }\n\"\"\"\n\n# First request - fetches from server\nresponse = client.post(\n    \"https://api.example.com/graphql\",\n    json={\n        \"query\": query,\n        \"variables\": {\"userId\": \"123\"}\n    },\n    headers={\"X-Hishel-Body-Key\": \"true\"}\n)\n\n# Second request - served from cache\nresponse = client.post(\n    \"https://api.example.com/graphql\",\n    json={\n        \"query\": query,\n        \"variables\": {\"userId\": \"123\"}\n    },\n    headers={\"X-Hishel-Body-Key\": \"true\"}\n)\n\n# Different variables - creates new cache entry\nresponse = client.post(\n    \"https://api.example.com/graphql\",\n    json={\n        \"query\": query,\n        \"variables\": {\"userId\": \"456\"}\n    },\n    headers={\"X-Hishel-Body-Key\": \"true\"}\n)\n</code></pre>"},{"location":"integrations/graphql/#global-configuration","title":"Global Configuration","text":"<p>Enable body-based caching for all requests using FilterPolicy:</p> <pre><code>from hishel.httpx import SyncCacheClient\nfrom hishel import FilterPolicy\n\n# All requests will use body in cache key through FilterPolicy\nclient = SyncCacheClient(policy=FilterPolicy(use_body_key=True))\n\nquery = \"\"\"\n    query GetPosts($limit: Int!) {\n        posts(limit: $limit) {\n            id\n            title\n            content\n        }\n    }\n\"\"\"\n\n# No need to set headers - body caching is automatic\nresponse = client.post(\n    \"https://api.example.com/graphql\",\n    json={\n        \"query\": query,\n        \"variables\": {\"limit\": 10}\n    }\n)\n</code></pre>"},{"location":"integrations/graphql/#async-support","title":"Async Support","text":"<p>Hishel fully supports async GraphQL clients:</p> <pre><code>from hishel.httpx import AsyncCacheClient\nfrom hishel import FilterPolicy\n\nasync def fetch_user_data():\n    async with AsyncCacheClient(policy=FilterPolicy(use_body_key=True)) as client:\n        query = \"\"\"\n            query GetUser($id: ID!) {\n                user(id: $id) {\n                    name\n                    email\n                    posts {\n                        title\n                        createdAt\n                    }\n                }\n            }\n        \"\"\"\n\n        response = await client.post(\n            \"https://api.example.com/graphql\",\n            json={\n                \"query\": query,\n                \"variables\": {\"id\": \"user-123\"}\n            }\n        )\n\n        return response.json()\n</code></pre>"},{"location":"integrations/graphql/#working-with-graphql-libraries","title":"Working with GraphQL Libraries","text":""},{"location":"integrations/graphql/#gql-gql-library","title":"GQL (gql) Library","text":"<p>The gql library is a GraphQL client for Python that provides advanced features like query validation, automatic retries, and more. Hishel integrates seamlessly with gql through HTTPX transports.</p>"},{"location":"integrations/graphql/#why-use-hishel-with-gql","title":"Why Use Hishel with GQL?","text":"<ul> <li>Automatic Query Caching: Cache identical GraphQL queries without manual implementation</li> <li>Network Efficiency: Reduce API calls and improve response times</li> <li>Cost Savings: Fewer requests to rate-limited or paid GraphQL APIs</li> <li>Offline Support: Serve cached responses when network is unavailable</li> </ul>"},{"location":"integrations/graphql/#basic-integration","title":"Basic Integration","text":"<p>You can integrate Hishel with gql in two ways:</p> <p>Method 1: Using Cached HTTPX Client (Recommended)</p> AsyncSync <pre><code>import asyncio\nfrom gql import gql, Client\nfrom gql.transport.httpx import HTTPXAsyncTransport\nfrom hishel.httpx import AsyncCacheClient\nfrom hishel import FilterPolicy\n\nasync def main():\n    # Create a cached HTTPX client\n    httpx_client = AsyncCacheClient(policy=FilterPolicy(use_body_key=True))\n\n    # Use it as transport for GQL\n    transport = HTTPXAsyncTransport(\n        url=\"https://api.example.com/graphql\",\n        client=httpx_client\n    )\n\n    async with Client(\n        transport=transport,\n        fetch_schema_from_transport=True\n    ) as client:\n        # Execute queries - automatic caching\n        query = gql(\"\"\"\n            query GetCountries {\n                countries {\n                    code\n                    name\n                    capital\n                }\n            }\n        \"\"\")\n\n        result = await client.execute(query)\n        print(result)\n\nasyncio.run(main())\n</code></pre> <pre><code>from gql import gql, Client\nfrom gql.transport.httpx import HTTPXTransport\nfrom hishel.httpx import SyncCacheClient\nfrom hishel import FilterPolicy\n\n# Create a cached HTTPX client\nhttpx_client = SyncCacheClient(policy=FilterPolicy(use_body_key=True))\n\n# Use it as transport for GQL\ntransport = HTTPXTransport(\n    url=\"https://api.example.com/graphql\",\n    client=httpx_client\n)\n\nclient = Client(transport=transport, fetch_schema_from_transport=True)\n\n# Execute queries - automatic caching\nquery = gql(\"\"\"\n    query GetCountries {\n        countries {\n            code\n            name\n            capital\n        }\n    }\n\"\"\")\n\nresult = client.execute(query)\nprint(result)\n</code></pre> <p>Method 2: Using CacheTransport (More Control)</p> <p>This approach gives you fine-grained control over the transport layer:</p> AsyncSync <pre><code>import asyncio\nfrom gql import gql, Client\nfrom gql.transport.httpx import HTTPXAsyncTransport\nfrom httpx import AsyncHTTPTransport\nfrom hishel.httpx import AsyncCacheTransport\nfrom hishel import FilterPolicy\n\nasync def main():\n    # Create a caching transport\n    transport = HTTPXAsyncTransport(\n        url=\"https://countries.trevorblades.com/graphql\",\n        transport=AsyncCacheTransport(\n            next_transport=AsyncHTTPTransport(),\n            policy=FilterPolicy(),  # Customize caching policy as needed\n        ),\n    )\n\n    # Create GQL client with caching transport\n    async with Client(\n        transport=transport,\n        fetch_schema_from_transport=True,\n    ) as session:\n        # Execute query\n        query = gql(\"\"\"\n            query getContinents {\n              continents {\n                code\n                name\n              }\n            }\n        \"\"\")\n\n        # First execution - fetches from server\n        result = await session.execute(query)\n        print(\"First request:\", result)\n\n        # Second execution - served from cache\n        result = await session.execute(query)\n        print(\"Second request (cached):\", result)\n\nasyncio.run(main())\n</code></pre> <pre><code>from gql import gql, Client\nfrom gql.transport.httpx import HTTPXTransport\nfrom httpx import HTTPTransport\nfrom hishel.httpx import SyncCacheTransport\nfrom hishel import FilterPolicy\n\n# Create a caching transport\ntransport = HTTPXTransport(\n    url=\"https://countries.trevorblades.com/graphql\",\n    transport=SyncCacheTransport(\n        next_transport=HTTPTransport(),\n        policy=FilterPolicy(use_body_key=True)  # Customize caching policy as needed\n    ),\n)\n\n# Create GQL client with caching transport\nwith Client(\n    transport=transport,\n    fetch_schema_from_transport=True,\n) as session:\n    # Execute query\n    query = gql(\"\"\"\n        query getContinents {\n          continents {\n            code\n            name\n          }\n        }\n    \"\"\")\n\n    # First execution - fetches from server\n    result = session.execute(query)\n    print(\"First request:\", result)\n\n    # Second execution - served from cache\n    result = session.execute(query)\n    print(\"Second request (cached):\", result)\n</code></pre>"},{"location":"integrations/graphql/#real-world-example-github-graphql-api","title":"Real-World Example: GitHub GraphQL API","text":"<p>Here's a complete example querying the GitHub GraphQL API with caching:</p> AsyncSync <pre><code>import asyncio\nfrom gql import gql, Client\nfrom gql.transport.httpx import HTTPXAsyncTransport\nfrom hishel.httpx import AsyncCacheClient\nfrom hishel import AsyncSqliteStorage, FilterPolicy\n\nasync def fetch_github_repos(username: str, token: str):\n    # Create cached client with persistent storage\n    client = AsyncCacheClient(\n        policy=FilterPolicy(use_body_key=True),\n        storage=AsyncSqliteStorage(\n            database_path=\"github_cache.db\",\n            default_ttl=3600.0  # Cache for 1 hour\n        )\n    )\n\n    transport = HTTPXAsyncTransport(\n        url=\"https://api.github.com/graphql\",\n        headers={\"Authorization\": f\"Bearer {token}\"},\n        client=client\n    )\n\n    async with Client(\n        transport=transport,\n        fetch_schema_from_transport=False,  # GitHub doesn't support introspection\n    ) as session:\n        query = gql(\"\"\"\n            query GetUserRepos($username: String!) {\n              user(login: $username) {\n                repositories(first: 10, orderBy: {field: UPDATED_AT, direction: DESC}) {\n                  nodes {\n                    name\n                    description\n                    stargazerCount\n                    url\n                  }\n                }\n              }\n            }\n        \"\"\")\n\n        result = await session.execute(\n            query,\n            variable_values={\"username\": username}\n        )\n\n        return result\n\n# Usage\nasyncio.run(fetch_github_repos(\"karpetrosyan\", \"your_token_here\"))\n</code></pre> <pre><code>from gql import gql, Client\nfrom gql.transport.httpx import HTTPXTransport\nfrom hishel.httpx import SyncCacheClient\nfrom hishel import SyncSqliteStorage, FilterPolicy\n\ndef fetch_github_repos(username: str, token: str):\n    # Create cached client with persistent storage\n    client = SyncCacheClient(\n        policy=FilterPolicy(use_body_key=True),\n        storage=SyncSqliteStorage(\n            database_path=\"github_cache.db\",\n            default_ttl=3600.0  # Cache for 1 hour\n        )\n    )\n\n    transport = HTTPXTransport(\n        url=\"https://api.github.com/graphql\",\n        headers={\"Authorization\": f\"Bearer {token}\"},\n        client=client\n    )\n\n    with Client(\n        transport=transport,\n        fetch_schema_from_transport=False,  # GitHub doesn't support introspection\n    ) as session:\n        query = gql(\"\"\"\n            query GetUserRepos($username: String!) {\n              user(login: $username) {\n                repositories(first: 10, orderBy: {field: UPDATED_AT, direction: DESC}) {\n                  nodes {\n                    name\n                    description\n                    stargazerCount\n                    url\n                  }\n                }\n              }\n            }\n        \"\"\")\n\n        result = session.execute(\n            query,\n            variable_values={\"username\": username}\n        )\n\n        return result\n\n# Usage\nfetch_github_repos(\"karpetrosyan\", \"your_token_here\")\n</code></pre>"},{"location":"integrations/graphql/#advanced-custom-graphql-filters","title":"Advanced: Custom GraphQL Filters","text":"<p>For fine-grained control over GraphQL caching, you can create custom filters that inspect query bodies and response content. This is useful when you want to:</p> <ul> <li>Cache only queries (not mutations)</li> <li>Skip caching queries with errors</li> </ul>"},{"location":"integrations/graphql/#example-cache-only-successful-queries","title":"Example: Cache Only Successful Queries","text":"<pre><code>import json\nfrom hishel import FilterPolicy, BaseFilter, Request, Response\nfrom hishel.httpx import AsyncCacheClient\n\nclass GraphQLQueryFilter(BaseFilter[Request]):\n    \"\"\"Only cache GraphQL queries (not mutations).\"\"\"\n\n    def needs_body(self) -&gt; bool:\n        return True\n\n    def apply(self, item: Request, body: bytes | None) -&gt; bool:\n        if body is None:\n            return False\n\n        try:\n            data = json.loads(body)\n            query = data.get(\"query\", \"\")\n            # Cache only if it's a query, not a mutation\n            return \"mutation\" not in query.lower()\n        except json.JSONDecodeError:\n            return False\n\n\nclass GraphQLSuccessFilter(BaseFilter[Response]):\n    \"\"\"Only cache successful GraphQL responses (no errors).\"\"\"\n\n    def needs_body(self) -&gt; bool:\n        return True\n\n    def apply(self, item: Response, body: bytes | None) -&gt; bool:\n        if item.status_code != 200 or body is None:\n            return False\n\n        try:\n            data = json.loads(body)\n            # Cache only if there are no GraphQL errors\n            return \"errors\" not in data\n        except json.JSONDecodeError:\n            return False\n\n\n# Create the policy with custom filters\npolicy = FilterPolicy(\n    request_filters=[GraphQLQueryFilter()],\n    response_filters=[GraphQLSuccessFilter()],\n    use_body_key=True,  # Enable body-based cache keys\n)\n\n# Use with HTTPX\nasync with AsyncCacheClient(policy=policy) as client:\n    # This query will be cached (successful query)\n    response = await client.post(\n        \"https://api.example.com/graphql\",\n        json={\n            \"query\": \"{ user(id: 1) { name email } }\"\n        }\n    )\n\n    # This mutation will NOT be cached (contains 'mutation')\n    response = await client.post(\n        \"https://api.example.com/graphql\",\n        json={\n            \"query\": \"mutation { updateUser(id: 1, name: \\\"John\\\") { id } }\"\n        }\n    )\n</code></pre> <p>This approach gives you complete control over what gets cached based on both request and response content.</p> <p>Learn More About Filters</p> <p>For more examples of custom filters and detailed documentation, see the Policies Guide.</p>"},{"location":"integrations/graphql/#best-practices","title":"Best Practices","text":"<ol> <li>Use <code>FilterPolicy(use_body_key=True)</code> for GraphQL clients to enable body-based caching</li> <li>Don't cache mutations - Use <code>Cache-Control: no-store</code> or disable caching for mutations</li> <li>Set appropriate TTLs - GraphQL responses may vary in freshness requirements</li> <li>Monitor cache hit rates - Check <code>hishel_from_cache</code> in response extensions</li> <li>Consider query complexity - More complex queries benefit more from caching</li> </ol>"},{"location":"integrations/graphql/#see-also","title":"See Also","text":"<ul> <li>Request/Response Metadata</li> <li>Storage Backends</li> <li>HTTPX Integration</li> <li>ASGI Integration</li> </ul>"},{"location":"integrations/httpx/","title":"HTTPX Integration","text":"<p>Hishel provides seamless integration with HTTPX, adding RFC 9111-compliant HTTP caching to your HTTPX applications with minimal code changes.</p>"},{"location":"integrations/httpx/#quick-start","title":"Quick Start","text":"<p>The easiest way to add caching to your HTTPX application is using the cache-enabled client classes:</p> SyncAsync <pre><code>from hishel.httpx import SyncCacheClient\n\nclient = SyncCacheClient()\n\n# First request - fetches from origin\nresponse = client.get(\"https://api.example.com/data\")\nprint(response.extensions[\"hishel_from_cache\"])  # False\n\n# Second request - served from cache\nresponse = client.get(\"https://api.example.com/data\")\nprint(response.extensions[\"hishel_from_cache\"])  # True\n</code></pre> <pre><code>from hishel.httpx import AsyncCacheClient\n\nasync with AsyncCacheClient() as client:\n    # First request - fetches from origin\n    response = await client.get(\"https://api.example.com/data\")\n    print(response.extensions[\"hishel_from_cache\"])  # False\n\n    # Second request - served from cache\n    response = await client.get(\"https://api.example.com/data\")\n    print(response.extensions[\"hishel_from_cache\"])  # True\n</code></pre> <p>That's it! Hishel automatically caches responses according to RFC 9111 rules.</p>"},{"location":"integrations/httpx/#cache-clients","title":"Cache Clients","text":"<p>Hishel provides drop-in replacements for HTTPX's <code>Client</code> and <code>AsyncClient</code>:</p> <ul> <li><code>SyncCacheClient</code> - Synchronous caching client</li> <li><code>AsyncCacheClient</code> - Asynchronous caching client</li> </ul> <p>These clients inherit from HTTPX clients and accept all the same parameters, plus additional caching configuration.</p> SyncAsync <pre><code>from hishel.httpx import SyncCacheClient\n\n# Create client with default settings\nclient = SyncCacheClient()\n\n# Make requests as usual\nresponse = client.get(\"https://api.example.com/users\")\n\n# All HTTPX methods work\nclient.post(\"https://api.example.com/data\", json={\"key\": \"value\"})\nclient.put(\"https://api.example.com/resource/1\", data=\"content\")\n\n# Or use context manager\nwith SyncCacheClient() as client:\n    response = client.get(\"https://api.example.com/data\")\n</code></pre> <pre><code>from hishel.httpx import AsyncCacheClient\n\n# Create client with default settings\nclient = AsyncCacheClient()\n\n# Make requests as usual\nresponse = await client.get(\"https://api.example.com/users\")\n\n# All HTTPX async methods work\n\nawait client.post(\"https://api.example.com/data\", json={\"key\": \"value\"})\nawait client.put(\"https://api.example.com/resource/1\", data=\"content\")\n\n# Or use context manager (recommended)\nasync with AsyncCacheClient() as client:\n    response = await client.get(\"https://api.example.com/data\")\n</code></pre>"},{"location":"integrations/httpx/#cache-transports","title":"Cache Transports","text":"<p>For more control or to integrate with existing HTTPX clients, use cache transports directly:</p> SyncAsync <pre><code>import httpx\nfrom hishel import SyncSqliteStorage\nfrom hishel.httpx import SyncCacheTransport\n\n# Create transport with caching\ntransport = SyncCacheTransport(\n    next_transport=httpx.HTTPTransport(),\n    storage=SyncSqliteStorage(),\n)\n\n# Use with standard HTTPX client\nclient = httpx.Client(transport=transport)\n\nresponse = client.get(\"https://api.example.com/data\")\n</code></pre> <pre><code>import httpx\nfrom hishel import AsyncSqliteStorage\nfrom hishel.httpx import AsyncCacheTransport\n\n# Create transport with caching\ntransport = AsyncCacheTransport(\n    next_transport=httpx.AsyncHTTPTransport(),\n    storage=AsyncSqliteStorage(),\n)\n\n# Use with standard HTTPX client\nclient = httpx.AsyncClient(transport=transport)\n\nresponse = await client.get(\"https://api.example.com/data\")\n</code></pre>"},{"location":"integrations/httpx/#see-also","title":"See Also","text":"<ul> <li>Metadata Reference - Complete guide to caching metadata</li> <li>Storage Documentation - Storage backend configuration</li> <li>Specification - RFC 9111 state machine</li> <li>HTTPX Documentation - Official HTTPX docs</li> </ul>"},{"location":"integrations/requests/","title":"Requests Integration","text":"<p>Hishel provides seamless integration with Requests, adding RFC 9111-compliant HTTP caching to your Requests applications with minimal code changes.</p>"},{"location":"integrations/requests/#quick-start","title":"Quick Start","text":"<p>Add caching to your Requests application using the <code>CacheAdapter</code>:</p> <pre><code>import requests\nfrom hishel.requests import CacheAdapter\n\n# Create session with cache adapter\nsession = requests.Session()\nsession.mount(\"https://\", CacheAdapter())\nsession.mount(\"http://\", CacheAdapter())\n\n# First request - fetches from origin\nresponse = session.get(\"https://api.example.com/data\")\nprint(response.headers.get(\"X-Hishel-From-Cache\"))  # None\n\n# Second request - served from cache\nresponse = session.get(\"https://api.example.com/data\")\nprint(response.headers.get(\"X-Hishel-From-Cache\"))  # True\n</code></pre> <p>That's it! Hishel automatically caches responses according to RFC 9111 rules.</p>"},{"location":"integrations/requests/#cache-adapter","title":"Cache Adapter","text":"<p>Hishel provides <code>CacheAdapter</code>, a custom HTTPAdapter that adds caching to Requests sessions.</p>"},{"location":"integrations/requests/#basic-usage","title":"Basic Usage","text":"<pre><code>import requests\nfrom hishel.requests import CacheAdapter\n\n# Create a session\nsession = requests.Session()\n\n# Mount cache adapter for HTTP and HTTPS\nadapter = CacheAdapter()\nsession.mount(\"https://\", adapter)\nsession.mount(\"http://\", adapter)\n\n# Make requests as usual\nresponse = session.get(\"https://api.example.com/users\")\n\n# All requests methods work\nsession.post(\"https://api.example.com/data\", json={\"key\": \"value\"})\nsession.put(\"https://api.example.com/resource/1\", data=\"content\")\n\n# Close when done\nsession.close()\n</code></pre> <p>Using Context Manager:</p> <pre><code>import requests\nfrom hishel.requests import CacheAdapter\n\nwith requests.Session() as session:\n    session.mount(\"https://\", CacheAdapter())\n    session.mount(\"http://\", CacheAdapter())\n\n    response = session.get(\"https://api.example.com/data\")\n    print(response.json())\n</code></pre>"},{"location":"integrations/requests/#see-also","title":"See Also","text":"<ul> <li>Metadata Reference - Complete guide to caching metadata</li> <li>Storage Documentation - Storage backend configuration</li> <li>Specification - RFC 9111 state machine</li> <li>HTTPX Integration - Alternative async HTTP client</li> <li>Requests Documentation - Official Requests docs</li> </ul>"}]}